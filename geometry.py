# GEOMETRY MODULE


#! IMPORTS


from .regression import LinearRegression
from .processing import interpolate_cs
from itertools import product
from typing import Tuple
from scipy.spatial.transform import Rotation as R
import weakref
import numpy as np
import pandas as pd
import plotly.express as px


#! CLASSES


class _Indexer:
    """
    Wrapper of the pandas.DataFrame .loc/.iloc class object which allows the
    use of the .loc/.iloc operator on Vector and Segment objects.

    Parameters
    ----------
    attr: str
        the name of the attribute to which the indexer is mapped for.
        (e.g. "loc" or "iloc")

    obj: Vector, Segment
        the object instance whose attributes must be mapped to .(attr)

    attributes: keyworded objects
        list of named objects being the attributes pointing to loc.
    """

    def __init__(self, attr, obj, **attributes):
        """
        constructor
        """
        assert isinstance(attr, str), "'attr' must be a str instance."
        self.attr = attr
        txt = "obj must be an GeometricObject instance."
        assert isinstance(obj, GeometricObject), txt
        self.obj = obj
        self.attributes = {}
        for i, v in attributes.items():
            txt = "The {} attribute is not part of obj.".format(i)
            assert hasattr(obj, i), txt
            self.attributes[i] = v

    def __setitem__(self, item, value):
        """
        set the items of all attributes of the object to value.

        Parameters
        ----------
        item: str
            the name of the item to be set.

        value: Any
            the value to be set on attr.
        """
        for i, v in self.attributes.items():
            if isinstance(value, self.obj.__class__):
                val = getattr(value, i).values
            else:
                val = value
            getattr(v, self.attr)[item] = val

    def __getitem__(self, item):
        """
        get the items of all attributes of the object to value.

        Parameters
        ----------
        item: str
            the name of the item to be returned.

        Returns
        -------
        obj: Vector, Segment
            the value associated to the requried item.
        """
        obj = self.obj.copy()
        for i, v in self.attributes.items():
            setattr(obj, i, getattr(v, self.attr)[item])
        return obj


class UnitDataFrame(pd.DataFrame):
    """
    Generate an object reflecting a custom DataFrame with unit of measurement.

    Parameters
    ----------
    data: np.ndarray (structured or homogeneous), Iterable, dict, or DataFrame
        Dict can contain Series, arrays, constants, dataclass or list-like
        objects. If data is a dict, column order follows insertion-order.
        If a dict contains Series which have an index defined, it is aligned
        by its index.

    index: Index or array-like
        Index to use for resulting frame. Will default to RangeIndex if no
        indexing information part of input data and no index provided.

    columns: Index or array-like
        Column labels to use for resulting frame when data does not have them,
        defaulting to RangeIndex(0, 1, 2, …, n). If data contains column
        labels, will perform column selection instead.

    unit: str
        the unit of measurement of the data.
    """

    _cacher = ()

    dtype = np.float64

    _metadata = ["unit"]

    unit = ""

    def _set_as_cached(self, item, cacher) -> None:
        """
        Set the _cacher attribute on the calling object with a weakref to
        cacher.
        """
        self._cacher = (item, weakref.ref(cacher))

    @property
    def _constructor(self):
        return UnitDataFrame

    @property
    def _constructor_sliced(self):
        return UnitDataFrame

    @property
    def T(self):
        """
        return the transpose of the object
        """
        return super(UnitDataFrame, self).T

    @property
    def norm(self):
        """
        get the norm of the UnitDataFrame.
        """
        dt = np.sqrt(np.sum(self.values ** 2, axis=1))
        lbls = [str(i) for i in self.columns.to_list()]
        cols = "|{}|".format("+".join(lbls))
        idx = self.index
        return UnitDataFrame(
            coordinates=dt,
            columns=[cols],
            index=idx,
            unit=self.unit,
        )

    @property
    def ndim(self):
        """
        return the number of dimensions of the object.
        """
        return len(self.columns)

    @property
    def nsamp(self):
        """
        return the number of samples of the object.
        """
        return len(self.index)

    @classmethod
    def unstack(cls, df):
        """
        convert a long format DataFrame into a UnitDataFrame instance.

        Parameters
        ----------
        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            .stack() method.

        Returns
        -------
        obj: _Ds
            the instance resulting from the dataframe reading.
        """
        unit = np.unique(df["Unit"].values.flatten())[0]
        tmp = df.copy().drop("Unit", axis=1)
        out = tmp.pivot("Time", "Dimension", "Amplitude")
        out.columns = pd.Index(out.columns.to_numpy())
        out.index = pd.Index(out.index.to_numpy())
        return cls(out, unit=unit)

    def stack(self):
        """
        stack the dataframe in long format.
        """
        out = pd.DataFrame(self, copy=True)
        out.insert(0, "Time", out.index.to_numpy())
        out = out.melt(
            id_vars="Time",
            value_vars=self.columns.to_numpy(),
            var_name="Dimension",
            value_name="Amplitude",
            ignore_index=True,
        )
        out.insert(out.shape[1] - 1, "Unit", np.tile(self.unit, out.shape[0]))
        return out

    def pivot(self):
        """
        create a wide df view of the data.
        """
        out = pd.DataFrame(self)
        cols = [i + " ({})".format(self.unit) for i in out.columns]
        out.columns = pd.Index(cols)
        return out

    def __str__(self):
        """
        support to print
        """
        return self.pivot().__str__()

    def matches(self, obj) -> bool:
        """
        check whether the object is similar to self.

        Parameters
        ----------
        obj: 2D numpy.ndarray, pandas.DataFrame, UnitDataFrame
            the object to be compared with self.

        Returns
        -------
        out: bool
            True if obj has the same shape and, if appropriate, the same
            index and columns of self.
        """
        valid = (np.ndarray, pd.DataFrame, UnitDataFrame)
        if not isinstance(obj, valid):
            return False
        if obj.ndim != self.ndim:
            return False
        if obj.shape[0] != self.shape[0]:
            return False
        if not isinstance(obj, np.ndarray):
            if not all([i == v for i, v in zip(self.columns, obj.columns)]):
                return False
            if not all([i == v for i, v in zip(self.index, obj.index)]):
                return False
        if isinstance(obj, UnitDataFrame):
            if self.unit != obj.unit:
                return False
        return True

    def _angles(self):
        """
        return the angle between all dimensions through the arctan function.

        Returns
        -------
        q: UnitDataFrame
            the UnitDataFrame containing the angles in radiants.
        """
        q = {}
        for i, c0 in self.columns.to_numpy()[:-1]:
            for j, c1 in self.columns.to_numpy()[1:]:
                lbl = "{}/{}".format(i, j)
                y = self[c0].values.flatten()
                x = self[c1].values.flatten()
                val = np.arctan2(y, x)
                q[lbl] = val
        return UnitDataFrame(q, index=self.index, unit="rad")

    def __init__(
        self,
        data,
        index=None,
        columns=None,
        unit="",
        *args,
        **kwargs,
    ):
        if any([i == "name" for i in kwargs]):
            args = [pd.Series(*args, **kwargs)]
            kwargs = {}
        super(UnitDataFrame, self).__init__(
            data=data,
            index=index,
            columns=columns,
            *args,
            **kwargs,
        )
        assert isinstance(unit, str), "unit must be a str object."
        self.unit = unit

    def __radd__(self, obj):
        """
        right addition.
        """
        return self + obj

    def __rsub__(self, obj):
        """
        right subtraction.
        """
        return -self + obj

    def __rmul__(self, obj):
        """
        right multiplication.
        """
        return self * obj

    def __rtruediv__(self, obj):
        """
        right division.
        """

        return (self ** (-1)) * obj


class GeometricObject:
    """
    generic class used as interface for the implementation of common methods.

    Parameters
    ----------
    index: array-like | None
        the list of indices for each sample in the provided data

    columns: array-like | None
        the list of labels for each dimension of the provided data

    unit: str (optional)
        the unit of measurement related to the provided data

    attributes: keyworded arguments
        The list of arguments containing the data of the object.
        The key of the arguments will be used as attributes of the object.
        The values of each key must be of type list, numpy.ndarray,
        pandas.DataFrame, UnitDataFrame.
    """

    # list of attributes of the class which contain relevant data.
    # NOTE THESE ATTRIBUTES ARE CONSTANTS THAT SHOULD NOT BE MODIFIED
    _attributes = []

    def __init__(
        self,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
        unit: str = "",
        **attributes,
    ):
        """
        class constructor.
        """
        # populate the object with the input attributes
        objs = {}
        self._attributes = []
        for attr, value in attributes.items():
            pnt = self._get_data(value, index, columns, unit)
            setattr(self, attr, pnt)
            objs[attr] = getattr(self, attr)
            self._attributes += [attr]

        # set the indexers .loc and .iloc
        self.loc = _Indexer(attr="loc", obj=self, **objs)
        self.iloc = _Indexer(attr="iloc", obj=self, **objs)

    def __str__(self) -> str:
        """
        convert self to a string.
        """
        return self.pivot().__str__()

    def __len__(self):
        """
        return the length of the object.
        """
        return self.nsamp

    def __setitem__(self, item, value):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        value: any
            the value to be set for the provided item.
        """
        itm = self._get_item(item)

        try:
            self.loc.__setitem__(itm, value)
        except KeyError:
            try:
                self.loc.__setitem__(np.s_[:, itm], value)
            except (IndexError, AttributeError):
                try:
                    self.iloc.__setitem__(itm, value)
                except KeyError:
                    self.iloc.__setitem__(np.s_[:, itm], value)
        except (IndexError, AttributeError):
            try:
                self.iloc.__setitem__(itm, value)
            except KeyError:
                self.iloc.__setitem__(np.s_[:, itm], value)

    def __getitem__(self, item):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        Returns
        -------
        val: GeometricObject
            the (sliced) object.
        """
        itm = self._get_item(item)

        try:
            return self.loc.__getitem__(itm)
        except KeyError:
            try:
                return self.loc.__getitem__(np.s_[:, itm])
            except (ValueError, TypeError):
                try:
                    return self.iloc.__getitem__(itm)
                except KeyError:
                    return self.iloc.__getitem__(np.s_[:, itm])
        except (ValueError, TypeError):
            try:
                return self.iloc.__getitem__(itm)
            except KeyError:
                return self.iloc.__getitem__(np.s_[:, itm])

    def _get_item(self, item):
        """
        ensure that item is an iterable object.

        Parameters
        ----------
        item: Any
            the item attribute passed to __setitem__ or __getitem__.

        Returns
        -------
        itm: iterable
            an iterable version of item.
        """
        if isinstance(item, str) or not hasattr(item, "__iter__"):
            return [item]
        else:
            return item

    def _adjust_indices(self, idx: Tuple[list, np.ndarray]) -> np.ndarray:
        """
        adjust the input index or columns to be used for creating the object.

        Parameters
        ----------
        idx: list, numpy.ndarray
            a 1D list to be arranged properly for generating the object.

        Returns
        -------
        out: numpy.ndarray
            a 1D numpy.ndarray to be used for the generation of the object.
        """
        if isinstance(idx, list):
            out = np.array(idx)
        else:
            out = idx
        assert out.ndim < 2, "'array' must be a 1D array."
        return out

    def _get_data(
        self,
        data,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
        unit: str = "",
    ):
        """
        get the UnitDataFrame required to generate an attribute of the object.

        Parameters
        ----------
        data: np.ndarray (structured or homogeneous), Iterable, dict,
            or DataFrame Dict can contain Series, arrays, constants, dataclass
            or list-like objects.
            If data is a dict, column order follows insertion-order.
            If a dict contains Series which have an index defined, it is
            aligned by its index.

        index: Index or array-like
            Index to use for resulting frame. Will default to RangeIndex if no
            indexing information part of input data and no index provided.

        columns: Index or array-like
            Column labels to use for resulting frame when data does not have
            them, defaulting to RangeIndex(0, 1, 2, …, n). If data contains
            column labels, will perform column selection instead.

        unit: str (optional)
            the unit of measurement of the provided data.

        Returns
        -------
        out: UnitDataFrame
            a UnitDataFrame instance to be used as attribute of the object.
        """
        assert isinstance(unit, str), "unit must be a string."
        if isinstance(data, UnitDataFrame):
            out = data
        elif isinstance(data, pd.DataFrame):
            out = UnitDataFrame(data, unit=unit)
        elif isinstance(data, (list, np.ndarray)):

            # check the data
            if isinstance(data, list):
                val = np.array(data)
            elif isinstance(data, np.ndarray):
                val = data
            else:
                txt = "data must be an instance of "
                txt += "[List, numpy.ndarray, pandas.DataFrame, "
                txt += "UnitDataFrame]."
                raise ValueError(txt)
            if val.ndim == 1:
                val = np.atleast_2d(val).T
            elif val.ndim > 2:
                txt = "data must be a 1D or 2D array."
                raise ValueError(txt)

            # check the index
            if index is None:
                idx = np.arange(data.shape[0])
            else:
                idx = self._adjust_indices(index)
            txt = "index has length {}, but it should be {}."
            txt = txt.format(len(idx), val.shape[0])
            assert len(idx) == val.shape[0], txt

            # check the columns
            if columns is None:
                col = ["D{}".format(i + 1) for i in range(data.shape[1])]
                col = np.array(col)
            else:
                col = self._adjust_indices(columns)
            txt = "columns has length {}, but it should be {}."
            txt = txt.format(len(col), val.shape[1])
            assert len(col) == val.shape[1], txt

            # generate the UnitDataFrame object
            out = UnitDataFrame(data=val, index=idx, columns=col, unit=unit)

        else:
            txt = "'data' must be an instance of list, numpy.ndarray, "
            txt += "pandas.DataFrame or UnitDataFrame."
            raise TypeError(txt)

        return out

    def _replace_value(self, value):
        """
        internal method used by fillna which replaces the values
        by a constant.

        Parameters
        ----------
        value: float, int
            the value to be used for replacement.

        Returns
        -------
        obj: GeometricObject instance
            the object with missing data replaced by value.
        """
        assert isinstance(value, float, int), "value must be float or int."
        obj = self.copy()
        for attr in self._attributes:
            df = getattr(obj, attr)
            miss = df.isna()
            df.loc[miss] = value
            setattr(obj, attr, df)
        return obj

    def _replace_cubic_spline(self):
        """
        internal method used by fillna which replaces the values via
        cubic spline interpolation.

        Returns
        -------
        obj: GeometricObject instance
            the object with missing data replaced by value.
        """
        obj = self.copy()
        x_new = self.index
        x_old = self.dropna().index
        return obj.apply(interpolate_cs, x_old=x_old, x_new=x_new)

    def _replace_linear_regression(self, n: int, predictors: list):
        """
        internal method used by fillna which replaces the values via
        linear regression.

        Parameters
        ----------
        n: int
            the number of predictors to be used if predictors is not empty.

        predictors: list
            list of objects that can be matched with self and that can be used
            to obtain missing coordinates via multiple linear regression.

        Returns
        -------
        filled: GeometricObject
            the object without missing data.
        """

        # check the input data
        assert isinstance(n, int), "'n' must be an 'int'."
        txt = "'predictors' must be a non-empty list."
        assert isinstance(predictors, list), txt
        assert len(predictors) > 0, txt
        txt = "one or more predictors does not match with self."
        for p in predictors:
            assert self.matches(p, strict=False), txt

        # get mean absolute correlation between self and the predictors
        corrs = [np.mean(abs(self.corr(i).values)) for i in predictors]

        # keep the best n predictors
        best_idx = np.argsort(corrs)[::-1][:n]
        best_preds = []
        for i, v in enumerate(predictors):
            if i in best_idx:
                best_preds += [v.pivot()]
        x = pd.concat(best_preds, axis=1).values

        # get the predictive equation
        y = self.pivot().values
        valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
        lr = LinearRegression(y[valid], x[valid], True)

        # replace missing values
        d = self.ndim
        obj = self.copy()
        miss = np.array(self.loc[self.pivot().isna().any(1)].index)
        for i, attr in enumerate(self._attributes):
            df = getattr(obj, attr)
            cols = [i * d, i * (d + 1)]
            df.loc[miss, df.columns] = lr.predict(x[miss]).values[:, cols]
            setattr(obj, attr, df)
        return obj

    def pivot(self) -> pd.DataFrame:
        """
        generate a wide dataframe object containing both origin and
        amplitudes.
        """
        df = self.stack().pivot("Time", ["Source", "Dimension", "Unit"])
        df.columns = pd.Index([i[1:] for i in df.columns])
        df.index = pd.Index(df.index.to_numpy())
        return df

    def plot(
        self,
        as_subplots: bool = False,
        lines: bool = True,
        show: bool = True,
        width: int = 1280,
        height: int = 720,
    ):
        """
        generate a plotly plot representing the current object.

        Parameters
        ----------
        as_subplots: bool (default=False)
            should the dimensions of object be plotted as a single subplot?

        lines: bool (default=True)
            if True, only lines linking the samples are rendered. Otherwise,
            a scatter plot is rendered.

        show: bool (default=True)
            if True the generated figure is immediately plotted. Otherwise
            the generated object is returned

        width: int (default=1280)
            the width of the output figure in pixels

        height: int (default=720)
            the height of the output figure in pixels

        Returns
        -------
        None, if show = True. A plotly.Figure object, otherwise.
        """
        fun = px.line if lines else px.scatter
        df = self.stack()
        dims = df.loc[df.index, ["Dimension"]].values.flatten()
        unts = df.loc[df.index, ["Unit"]].values.flatten()
        vals = ["{} ({})".format(d, u) for d, u in zip(dims, unts)]
        df.loc[df.index, ["Dimension"]] = np.atleast_2d(vals).T
        fig = fun(
            data_frame=self.stack(),
            x="Time",
            y="Amplitude",
            color="Dimension",
            facet_row="Dimension" if as_subplots else None,
            facet_col="Source",
            width=width,
            height=height,
            template="simple_white",
        )
        fig.update_layout(showlegend=not as_subplots)
        if show:
            fig.show()
        else:
            return fig

    def describe(self, percentiles: list = []) -> pd.DataFrame:
        """
        provide descriptive statistics about the parameters in df.

        Parameters
        ----------
        percentiles: list
            a list of values in the [0, 1] range defining the desired
            percentiles to be calculated.

        Returns
        -------
        df: pd.DataFrame
            a pandas.DataFrame with the object descriptive statistics.
        """
        grp = self.stack().drop("Time", axis=1)
        grp = grp.groupby(["Source", "Dimension", "Unit"])
        df = grp.describe(percentiles=percentiles)
        df.columns = pd.Index([i[1] for i in df.columns])
        return df

    def matches(self, obj, strict=False) -> bool:
        """
        check if obj is comparable to self.

        Parameters
        ----------
        obj: Any
            the object to be compared

        strict: bool
            should a strict match be approached?
            Strict matching means that, in case of multiple attributes
            in the same GeometricObject, all attributes are required
            to match with self. Otherwise it is required that just
            one of the attributes matches with self.

        Returns
        -------
        Q: bool
            true if obj matches self, False otherwise.
        """
        a = [getattr(self, i) for i in self._attributes]
        if not isinstance(obj, (pd.DataFrame, UnitDataFrame, np.ndarray)):
            try:
                b = [getattr(obj, i) for i in obj._attributes]
            except Exception:
                return False
        else:
            b = [obj]
        combs = [i[0].matches(i[1]) for i in product(a, b)]

        return all(combs) if strict else any(combs)

    def corr(self, obj, weighted=True):
        """
        internal methoget the correlation between self and obj.

        Parameters
        ----------
        obj: numpy.ndarray, pandas.DataFrame, UnitDataFrame, GeometricObject
            the object to be correlated with self.

        weighted: bool
            should the correlation be weighted by the number of
            non-missing data?
            True means that the correlation value is multiplied by
            the percentage of non-missing data in the sample. False, otherwise.

        Returns
        -------
        r: pandas.DataFrame
            the correlation between self and obj.
        """
        txt = "'obj' must be matchable with self."
        assert self.matches(obj, strict=False), txt
        a = self.pivot()
        if isinstance(obj, np.ndarray):
            cols = [("Obj", "", str(i)) for i in range(obj.shape[1])]
            cols = pd.MultiIndex.from_tuples(cols)
            b = pd.DataFrame(obj, index=self.index, columns=cols)
        elif isinstance(obj, (pd.DataFrame, UnitDataFrame)):
            b = obj.copy()
            cols = [("Obj", "", i) for i in self]
            b.columns = pd.MultiIndex.from_tuples(cols)
        else:
            try:
                b = obj.pivot()
                cols = [("Obj", *i) for i in b]
                b.columns = pd.MultiIndex.from_tuples(cols)
            except Exception:
                txt = "correlation between {} and {} is not supported."
                txt = txt.format(*[i.__class__.__name__ for i in [self, obj]])
                raise NotImplementedError(txt)
        df = pd.DataFrame(pd.concat([a, b], axis=1))
        dfn = df.dropna(inplace=False)
        r = df.corr().iloc[: a.shape[1], b.shape[1] :]  # pearson's correlation
        if weighted:
            r *= dfn.shape[0] / df.shape[0]
        return r

    def stack(self) -> pd.DataFrame:
        """
        stack the object as a long format DataFrame.
        """
        df = []
        for attr in self._attributes:
            obj = getattr(self, attr).stack()
            obj.insert(0, "Source", np.tile(attr, obj.shape[0]))
            df += [obj]
        return pd.concat(df, axis=0, ignore_index=True)

    def copy(self):
        """
        make a copy of the object
        """
        return self.unstack(self.stack())

    def dropna(self):
        """
        return the object without missing data.
        """
        i = self.pivot().dropna().index.to_numpy()
        if len(i) == 0:
            out = self.copy()
            for attr in out.attributes:
                setattr(out, attr, getattr(out, attr).loc[i])
        else:
            out = self[i].copy()
        return out

    def has_na(self):
        """
        return the index of the samples containing missing data.
        """
        i = self.pivot().isna().any(1)
        return self[i].index

    def unique(self):
        """
        return the unique samples in the object.
        """
        i = np.unique(self.pivot().values, axis=0, return_index=True)[1]
        return self[i].copy()

    def apply(self, fun, *args, **kwargs):
        """
        apply fun to the object.

        Parameters
        ----------
        fun: function
            a callable object returning a 1D array with the same len as obj.

        args: Any
            arguments passed to fun

        kwargs: any
            named arguments passed to fun

        Returns
        -------
        obj: GeometricObject
            the object with the function applied to each attribute.
        """
        obj = self.copy()
        for attr in self._attributes:
            tmp = getattr(obj, attr).apply(fun, *args, **kwargs)
            setattr(obj, attr, tmp)
        return obj

    def fillna(
        self,
        value: Tuple[int, float] = None,
        n: int = 3,
        predictors: list = [],
    ):
        """
        fill missing values in the point.

        Parameters
        ----------
        value: float or None
            the value to be used for missing data replacement.
            if None, cubic spline interpolation is used to extract the
            missing data.
            Please note that if predictors is not empty, this parameter is
            ignored.

        n: int
            the number of predictors to be used if predictors is not empty

        predictors: list
            list of objects that can be matched with self and that can be used
            to obtain missing coordinates via multiple linear regression.
            If left empty, cubic spline interpolation or constant value
            substitution is used according to the inputs provided in value.

        Returns
        -------
        filled: GeometricObject
            the object without missing data.
        """

        # check if there are missing data in the object
        miss = self.has_na()
        if len(miss) == 0:
            return self.copy()

        # apply the appropriate replacement
        if value is not None:
            return self._replace_value(value)
        elif len(predictors) > 0:
            return self._replace_linear_regression(n, predictors)
        else:
            return self._replace_cubic_spline()

    @classmethod
    def unstack(cls, df: pd.DataFrame):
        """
        convert a long format DataFrame into an instance of the object.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            .stack() method.

        Returns
        -------

        obj: GeometricObject
            the instance resulting from the dataframe reading.
        """
        cols = ["Time", "Dimension", "Unit", "Amplitude"]
        objs = {}
        for attr in np.unique(df["Source"].values.flatten()):
            tmp = df.loc[df.isin([attr]).any(1)][cols]
            objs[attr] = UnitDataFrame.unstack(tmp)
        return cls(**objs)

    @property
    def attributes(self):
        """
        return the attributes of this instance.
        """
        return self._attributes

    @property
    def columns(self):
        """
        return the dimensions of the object.
        """
        return getattr(self, self._attributes[0]).columns.to_list()

    @property
    def index(self):
        """
        return the index of the object.
        """
        return getattr(self, self._attributes[0]).index.to_list()

    @property
    def shape(self):
        """
        return the shape of the object.
        """
        return getattr(self, self._attributes[0]).shape

    @property
    def ndim(self):
        """
        return the number of dimensions of the object.
        """
        return len(self.columns)

    @property
    def nsamp(self):
        """
        return the number of samples of the object.
        """
        return len(self.index)

    @property
    def sampling_frequency(self) -> float:
        """
        return the "average" sampling frequency of the object.
        """
        return float(1.0 / np.mean(np.diff(self.index)))


class ReferenceFrame(GeometricObject):
    """
    Create a ReferenceFrame instance.

    Parameters
    ----------

    origin: pd.DataFrame, UnitDataFrame, Point
        a pandas.DataFrame that contains the coordinates of the
        ReferenceFrame's origin at each time instant (index).

    unit: str
        the unit of measurement of the origin and the versors.

    versors: named pd.DataFrame, UnitDataFrame, Point, Vector
        a dict where each key is a valid object with shape equal to origin
        that contains coordinates of the versors defining the orientation
        of the reference frame at each time instant.
        The number of versors must be equal to the number of dimensions
        of 'origin'.
    """

    def __init__(
        self,
        origin,
        unit="",
        **versors,
    ):

        # check the origin
        txt = "'origin' must be an instance of (pandas.DataFrame, "
        txt += "UnitDataFrame or Point)."
        assert isinstance(origin, (UnitDataFrame, Point, pd.DataFrame)), txt
        if isinstance(origin, Point):
            ori = self._get_data(origin.coordinates)
        else:
            ori = self._get_data(origin, unit=unit)
        idx = ori.index
        col = ori.columns
        assert 2 <= len(col) <= 3, "only 2D and 3D frames are supported."

        # check the versors
        vrs = {}
        txt = "versors' keys must be the same as origin dimensions."
        for d in col:
            assert d in [i for i in versors], txt
            if isinstance(versors[d], Vector):
                v = versors[d].amplitude
            elif isinstance(versors[d], Point):
                v = versors[d].coordinates
            elif isinstance(versors[d], (pd.DataFrame, UnitDataFrame)):
                v = self._get_data(versors[d], unit=unit)
            txt2 = "{} versor does not match with origin.".format(d)
            assert ori.matches(v, strict=False), txt2
            vrs[d] = v.copy()

        # apply gram-schmidt normalization to the versors
        mat = np.zeros((len(idx), len(col), len(col)))
        for i, v in enumerate(idx):
            vers = np.vstack([k.loc[v].values.T for k in vrs.values()])
            norm = self._gram_schmidt(vers)
            for j, key in enumerate(vrs):
                vrs[key].loc[v, col] = norm[j]
            mat[i] = norm

        # generate the object
        super(ReferenceFrame, self).__init__(origin=ori, **vrs)

        # store the efficient scipy.Rotation class object allowing the
        # rotation of additional input segments.
        self._rotmat = R.from_matrix(mat)

    def _apply(self, obj, fun):
        """
        rotate the object.

        Parameters
        ----------
        obj: GeometricObject, UnitDataFrame
            the object to be rotated.

        fun: function
            the rotation function.

        Returns
        -------
        rot: GeometricObject, UnitDataFrame
            the rotated object.
        """
        if isinstance(obj, UnitDataFrame):
            txt = "obj doesn't match with the ReferenceFrame."
            assert self.matches(obj, strict=False), txt
            out = fun(obj)

        elif isinstance(obj, GeometricObject):
            out = obj.copy()
            for attr in out.attributes:
                setattr(out, attr, self._apply(getattr(out, attr), fun))

        else:
            txt = "obj has class {}, which cannot be aligned to"
            txt += "ReferenceFrame instances"
            txt = txt.format(obj.__class__.__name__)
            raise TypeError(txt)

        return out

    def _gram_schmidt(self, points: np.ndarray) -> np.ndarray:
        """
        Return the orthogonal basis defined by a set of points using the
        Gram-Schmidt algorithm.

        Parameters:
            points (np.ndarray): a NxN numpy.ndarray to be orthogonalized
            (by row).

        Returns:
            a NxN numpy.ndarray containing the orthogonalized arrays.
        """

        def proj(a, b):
            return (np.inner(a, b) / np.inner(b, b) * b).astype(float)

        def norm(v):
            return v / np.sqrt(np.sum(v ** 2))

        # calculate the projection points
        W = []
        for i, u in enumerate(points):
            w = np.copy(u).astype(float)
            for j in points[:i, :]:
                w -= proj(u, j)
            W += [w]

        # normalize
        return np.vstack([norm(u) for u in W])

    def apply_to(
        self,
        obj: Tuple[GeometricObject, UnitDataFrame],
    ) -> Tuple[GeometricObject, UnitDataFrame]:
        """
        Align the object to the current ReferenceFrame instance.

        Parameters
        ----------
        obj: UnitDataFrame, GeometricObject
            the object to be rotated.

        Returns
        -------
        rot: UnitDataFrame, GeometricObject
            the rotated object.
        """

        def fun(obj):
            if self.matches(obj, strict=True):
                return self._rotmat.apply(obj - self.origin)
            else:
                return self._rotmat.apply(obj)

        return self._apply(obj, fun)

    def invert(
        self,
        obj: Tuple[GeometricObject, UnitDataFrame],
    ) -> Tuple[GeometricObject, UnitDataFrame]:
        """
        Rotate the object back to the global ReferenceFrame.

        Parameters
        ----------
        obj: UnitDataFrame, GeometricObject
            the object to be rotated.

        Returns
        -------
        rot: UnitDataFrame, GeometricObject
            the rotated object.
        """

        def fun(obj):
            out = self._rotmat.inv().apply(obj)
            if self.matches(out, strict=True):
                out += self.origin
            return out

        return self._apply(obj, fun)

    @property
    def versors(self):
        """
        return the versors of the array as dict of Vector(s).
        """
        out = {}
        for attr in self._attributes:
            if attr != "origin":
                out[attr] = Vector(
                    amplitude=getattr(self, attr),
                    origin=self.origin,
                )
        return out


class GeometricMathObject(GeometricObject):
    """
    class extending the default GeometricObject instance by adding support
    to math operations.

    Parameters
    ----------
    index: array-like | None
        the list of indices for each sample in the provided data

    columns: array-like | None
        the list of labels for each dimension of the provided data

    unit: str
        the unit of measurement of the object's attributes

    attributes: keyworded arguments
        The list of arguments containing the data of the object.
        The key of the arguments will be used as attributes of the object.
        The values of each key must be of type list, numpy.ndarray,
        pandas.DataFrame, UnitDataFrame.
    """

    def __init__(
        self,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
        unit: str = "",
        **attributes,
    ):
        """
        constructor.
        """
        super(GeometricMathObject, self).__init__(
            index=index,
            columns=columns,
            unit=unit,
            **attributes,
        )

    @property
    def T(self):
        """
        return the transpose of the object
        """
        obj = self.copy()
        for attr in self._attributes:
            setattr(obj, attr, getattr(self, attr).T)
        return obj

    def _math_value(
        self,
        obj: Tuple[int, float, np.ndarray, UnitDataFrame, pd.DataFrame],
        transpose: bool = False,
    ) -> np.ndarray:
        """
        hidden function used to extract the values to be used
        for math operations with segments.

        Parameters
        ----------
        obj: int, float, np.ndarray, UnitDataFrame, pd.DataFrame
            the second object included in the math operation.

        transpose: bool (optional, default=False)
            if True, the transpose of obj is checked. Otherwise the
            obj data is controlled as is.

        Returns
        -------
        val: np.ndarray
            the value to be used for the math operation.
        """
        if isinstance(obj, (UnitDataFrame, pd.DataFrame)):
            val = obj.values
        elif isinstance(obj, (int, float, np.ndarray)):
            val = obj
        else:
            txt = "operations with {} objects are not supported."
            txt = txt.format(obj.__class__.__name__)
            raise TypeError(txt)
        val = val * np.ones(self.shape)
        txt = "obj does not match with self."
        assert self.matches(val.T if transpose else val, strict=True), txt
        return val

    def __iadd__(self, obj):
        """
        iterative addition.
        """
        self = self + obj
        return self

    def __radd__(self, obj):
        """
        right addition.
        """
        return self + obj

    def __isub__(self, obj):
        """
        iterative subtraction.
        """
        self = self - obj
        return self

    def __rsub__(self, obj):
        """
        right subtraction.
        """
        return -self + obj

    def __imul__(self, obj):
        """
        iterative multiplication.
        """
        self = self * obj
        return self

    def __rmul__(self, obj):
        """
        right multiplication.
        """
        return self * obj

    def __itruediv__(self, obj):
        """
        iterative division.
        """
        self = self / obj
        return self

    def __rtruediv__(self, obj):
        """
        iterative division.
        """

        return (self ** (-1)) * obj

    def __ifloordiv__(self, obj):
        """
        iterative floor division.
        """
        self = self / obj
        return self

    def __abs__(self):
        """
        absolute value
        """
        obj = self.copy()
        for attr in self._attributes:
            setattr(obj, attr, abs(getattr(self, attr)))
        return obj

    def __neg__(self):
        """
        negative of self (- operator).
        """
        return self * (-1)

    def __pos__(self):
        """
        positive of self (+ operator).
        """
        return self * (1)

    def __truth__(self):
        """
        truth (identity) operator.
        """
        return self

    def __add__(self, obj):
        """
        addition.
        """
        raise NotImplementedError

    def __sub__(self, obj):
        """
        subtraction.
        """
        raise NotImplementedError

    def __mul__(self, obj):
        """
        multiplication
        """
        raise NotImplementedError

    def __truediv__(self, obj):
        """
        division
        """
        raise NotImplementedError

    def __floordiv__(self, obj):
        """
        floor division
        """
        raise NotImplementedError

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        raise NotImplementedError

    def __mod__(self, obj):
        """
        module (% operator).
        """
        raise NotImplementedError

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        raise NotImplementedError


class Point(GeometricMathObject):
    """
    Generate an object reflecting a dimension-less point
    in a n-dimensional space.

    Parameters
    ----------
    coordinates: np.ndarray (structured or homogeneous), Iterable, dict,
        or DataFrame Dict can contain Series, arrays, constants, dataclass
        or list-like objects.
        If data is a dict, column order follows insertion-order.
        If a dict contains Series which have an index defined, it is aligned
        by its index.

    index: Index or array-like
        Index to use for resulting frame. Will default to RangeIndex if no
        indexing information part of input data and no index provided.

    columns: Index or array-like
        Column labels to use for resulting frame when data does not have them,
        defaulting to RangeIndex(0, 1, 2, …, n). If data contains column
        labels, will perform column selection instead.

    unit: str
        the unit of measurement of the coordinates of the point.
    """

    def __init__(self, coordinates, index=None, columns=None, unit=""):
        """
        constructor
        """
        super(Point, self).__init__(
            coordinates=coordinates,
            index=index,
            columns=columns,
            unit=unit,
        )

    def _math_value(self, obj, transpose: bool = False) -> np.ndarray:
        """
        Parameters
        ----------
        obj: int, float, np.ndarray, UnitDataFrame, pd.DataFrame, Vector
            the second object included in the math operation.

        transpose: bool (optional, default=False)
            if True, the transpose of obj is checked. Otherwise the
            obj data is controlled as is.

        Returns
        -------
        val: np.ndarray
            the value to be used for the math operation.
        """
        if isinstance(obj, Point):
            val = obj.coordinates
        else:
            val = obj
        return super(Point, self)._math_value(val, transpose)

    def __add__(self, obj):
        """
        addition.
        """
        return Point(coordinates=self.coordinates + self._math_value(obj))

    def __sub__(self, obj):
        """
        subtraction.
        """
        return Point(coordinates=self.coordinates - self._math_value(obj))

    def __mul__(self, obj):
        """
        multiplication
        """
        return Point(coordinates=self.coordinates * self._math_value(obj))

    def __truediv__(self, obj):
        """
        division
        """
        return Point(coordinates=self.coordinates / self._math_value(obj))

    def __floordiv__(self, obj):
        """
        floor division
        """
        return Point(coordinates=self.coordinates // self._math_value(obj))

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        return Point(coordinates=self.coordinates ** self._math_value(obj))

    def __mod__(self, obj):
        """
        module (% operator).
        """
        return Point(coordinates=self.coordinates % self._math_value(obj))

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        val = self._math_value(obj, transpose=True)
        return Point(coordinates=self.coordinates @ val)


class Vector(GeometricMathObject):
    """
    Generate an object reflecting a dimension-less vector in a n-dimensional
    space.

    Parameters
    ----------

    amplitude: Point, UnitDataFrame, pandas.DataFrame, numpy.ndarray, list
        the amplitude of the vector.

    origin: Point, UnitDataFrame, pandas.DataFrame, numpy.ndarray, list
        the origin of the vector.

    index: arraylike
        the index for both the amplitude and origin of the vector.

    columns: arraylike
        the name of the dimensions of the vector's origin and amplitude.

    unit: str
        the unit of measurement of the vector's origin and amplitude.
    """

    def __init__(
        self,
        amplitude: Tuple[Point, UnitDataFrame, pd.DataFrame, np.ndarray, list],
        origin: Tuple[UnitDataFrame, pd.DataFrame, np.ndarray, list] = None,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
        unit: str = "",
    ):
        if isinstance(amplitude, Point):
            amp = amplitude.coordinates
        else:
            amp = amplitude
        if isinstance(origin, Point):
            ori = origin.coordinates
        else:
            ori = origin
        super(Vector, self).__init__(
            amplitude=amp,
            origin=ori,
            index=index,
            columns=columns,
            unit=unit,
        )

    @property
    def norm(self) -> UnitDataFrame:
        """
        get the norm of the vector.
        """
        return (self.amplitude - self.origin).norm

    def angles(self) -> UnitDataFrame:
        """
        return the angles between all dimensions using the arctan function.
        """
        return (self.amplitude - self.origin)._angles()

    def _math_value(self, obj, transpose: bool = False) -> np.ndarray:
        """
        Parameters
        ----------
        obj: int, float, np.ndarray, UnitDataFrame, pd.DataFrame, Vector
            the second object included in the math operation.

        transpose: bool (optional, default=False)
            if True, the transpose of obj is checked. Otherwise the
            obj data is controlled as is.

        Returns
        -------
        val: np.ndarray
            the value to be used for the math operation.
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return super(Vector, self)._math_value(val, transpose)

    def __add__(self, obj):
        """
        addition.
        """
        return Vector(
            amplitude=self.amplitude + self._math_value(obj),
            origin=self.origin,
        )

    def __sub__(self, obj):
        """
        subtraction.
        """
        return Vector(
            amplitude=self.amplitude - self._math_value(obj),
            origin=self.origin,
        )

    def __mul__(self, obj):
        """
        multiplication
        """
        return Vector(
            amplitude=self.amplitude * self._math_value(obj),
            origin=self.origin,
        )

    def __truediv__(self, obj):
        """
        division
        """
        return Vector(
            amplitude=self.amplitude / self._math_value(obj),
            origin=self.origin,
        )

    def __floordiv__(self, obj):
        """
        floor division
        """
        return Vector(
            amplitude=self.amplitude // self._math_value(obj),
            origin=self.origin,
        )

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        return Vector(
            amplitude=self.amplitude ** self._math_value(obj),
            origin=self.origin,
        )

    def __mod__(self, obj):
        """
        module (% operator).
        """
        return Vector(
            amplitude=self.amplitude % self._math_value(obj),
            origin=self.origin,
        )

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        val = self._math_value(obj, transpose=True)
        return Vector(
            amplitude=self.amplitude @ val,
            origin=self.origin @ val,
        )


class Segment(GeometricMathObject):
    """
    Generate an object reflecting a segment a n-dimensional space.

    Parameters
    ----------

    p0, p1: Point, UnitDataFrame, pandas.DataFrame, numpy.ndarray, list
        the first and second points of the segment.

    index: arraylike
        the index for both the amplitude and origin of the vector.

    columns: arraylike
        the name of the dimensions of the vector's origin and amplitude.

    unit: str
        the unit of measurement of the coordinates defining the segment's
        ends.
    """

    def __init__(
        self,
        p0: Tuple[Point, UnitDataFrame, pd.DataFrame, np.ndarray, list],
        p1: Tuple[UnitDataFrame, pd.DataFrame, np.ndarray, list] = None,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
        unit: str = "",
    ):
        super(Segment, self).__init__(
            p0=p0.coordinates if isinstance(p0, Point) else p0,
            p1=p1.coordinates if isinstance(p1, Point) else p1,
            index=index,
            columns=columns,
            unit=unit,
        )

    @property
    def norm(self) -> UnitDataFrame:
        """
        get the norm of the segment.
        """
        return (self.p1 - self.p0).norm

    def angles(self) -> UnitDataFrame:
        """
        return the angles between all dimensions using the arctan function.
        """
        return (self.p1 - self.p0)._angles()

    def point_at(
        self,
        distance: Tuple[float, int],
        as_percentage: bool = True,
    ) -> Point:
        """
        get the point along the segment direction at the provided distance.

        Parameters
        ----------
        distance: float, int or array-like
            the required distance. If as_percentage is true, this value should
            be provided such as 0 means same as p0, and 1 same as p1.

        as_percentage: bool
            should the distance be considered as percentage of the segment's
            distance?

        Returns
        -------
        pnt: Point
            the Point instance object at the required distance.
        """

        # get the segment length
        n = self.norm

        # check the input data
        if not isinstance(distance, (float, int)):
            txt = "distance must be a float, int, Point, numpy.ndarray"
            txt += " UnitDataFrame or pandas.DataFrame."
            assert n.matches(distance, strict=True), txt
            if isinstance(distance, (Point, pd.DataFrame)):
                d = distance.values
            elif isinstance(distance, np.ndarray):
                d = distance
            else:
                raise ValueError(txt)
        else:
            d = distance * np.ones(n.shape)
        txt = "as_percentage must be a bool object."
        assert isinstance(as_percentage, bool), txt

        # get the point
        if not as_percentage:
            d = d / n.values

        # return the point
        return (self.p1 - self.p0) * d + self.p0

    def projection_of(self, pnt: Point) -> Point:
        """
        get the point being the orthogonal projection of pnt along the segment.

        Parameters
        ----------
        pnt: Point
            the point outside the current segment of which its projection
            is required.

        Returns
        -------
        pro: Point
            the Point instance object being the projection of pnt along the
            actual segment.
        """

        # check the input data
        assert isinstance(pnt, Point), "pnt must be a Point object."
        txt = "pnt does not match with the segment."
        assert self.matches(pnt, strict=True), txt

        # get the pnt-p0-p1 angle
        a = three_points_angle(pnt, self.p0, self.p1)

        # get the length of the cathethus starting from p0 and whose extremity
        # ends at the projection point.
        d = (pnt - self.p0) * np.cos(a.values)

        # get the projection point along the segment being ad distance "d".
        return self.point_at(distance=d, as_percentage=False)

    def _math_value(self, obj, transpose: bool = False) -> np.ndarray:
        """
        Parameters
        ----------
        obj: int, float, np.ndarray, UnitDataFrame, pd.DataFrame, Segment
            the second object included in the math operation.

        transpose: bool (optional, default=False)
            if True, the transpose of obj is checked. Otherwise the
            obj data is controlled as is.

        Returns
        -------
        v0, v1: np.ndarray
            the values to be used for the math operation.
        """
        if isinstance(obj, Segment):
            v0 = super(Vector, self)._math_value(obj.p0, transpose)
            v1 = super(Vector, self)._math_value(obj.p1, transpose)
        else:
            v0 = super(Vector, self)._math_value(obj, transpose)
            v1 = np.copy(v0)
        return v0, v1

    def __add__(self, obj):
        """
        addition.
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 + v0, p1=self.p1 + v1)

    def __sub__(self, obj):
        """
        subtraction.
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 - v0, p1=self.p1 - v1)

    def __mul__(self, obj):
        """
        multiplication
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 * v0, p1=self.p1 * v1)

    def __truediv__(self, obj):
        """
        division
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 / v0, p1=self.p1 / v1)

    def __floordiv__(self, obj):
        """
        floor division
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 / v0, p1=self.p1 / v1)

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 ** v0, p1=self.p1 ** v1)

    def __mod__(self, obj):
        """
        module (% operator).
        """
        v0, v1 = self._math_value(obj)
        return Segment(p0=self.p0 % v0, p1=self.p1 % v1)

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        v0, v1 = self._math_value(obj, transpose=True)
        return Segment(p0=self.p0 @ v0, p1=self.p1 @ v1)


#! METHODS


def three_points_angle(a: Point, b: Point, c: Point):
    """
    return the angle between 3 points using the cosine theorem.

    Parameters
    ----------
    a, b, c: Point
        the point objects.

    Returns
    -------
    q: UnitDataFrame
        the angle in radiants.
    """

    # check the data
    assert a.matches(b, strict=True), "a does not match b"
    assert a.matches(c, strict=True), "a does not match c"
    assert b.matches(c, strict=True), "b does not match c"

    # get the segments
    ab = (b - a).norm.values.flatten()
    bc = (b - c).norm.values.flatten()
    ac = (c - a).norm.values.flatten()

    # return the angle
    q = np.arccos((ac ** 2 - ab ** 2 - bc ** 2) / (-2 * ab * bc))
    return UnitDataFrame(
        q,
        columns=["Angle"],
        index=a.index,
        unit="rad",
    )
