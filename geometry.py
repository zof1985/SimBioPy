# GEOMETRY MODULE


#! IMPORTS

from .regression import LinearRegression
from .processing import interpolate_cs
from typing import Tuple
from scipy.spatial.transform import Rotation as R
import weakref
import numpy as np
import pandas as pd
import plotly.express as px


#! CLASSES


class _AbstractObject:
    """
    generic class used as interface for the implementation of common methods
    """

    def __str__(self) -> str:
        """
        convert self to a string.
        """
        raise NotImplementedError

    def stack(self) -> pd.DataFrame:
        """
        stack the object as a long format DataFrame.
        """
        raise NotImplementedError

    def unstack(df: pd.DataFrame):
        """
        convert a long format DataFrame into an instance of the object.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            _Object.stack() method.

        Returns
        -------

        obj: _Object subclass
            the _Object subclass instance resulting from the DataFrame reading.
        """
        raise NotImplementedError

    def dropna(self):
        """
        return the object without missing data.
        """
        raise NotImplementedError

    def unique(self):
        """
        return the unique elements of the object.
        """
        raise NotImplementedError

    def plot(
        self,
        as_subplots: bool = False,
        lines: bool = True,
        show: bool = True,
        width: int = 1280,
        height: int = 720,
    ):
        """
        generate a plotly plot representing the current object.

        Parameters
        ----------
        as_subplots: bool (default=False)
            should the dimensions of Point be plotted as a single subplot?

        lines: bool (default=True)
            if True, only lines linking the samples are rendered. Otherwise,
            a scatter plot is rendered.

        show: bool (default=True)
            if True the generated figure is immediately plotted. Otherwise the
            generated object is returned

        width: int (default=1280)
            the width of the output figure in pixels

        height: int (default=720)
            the height of the output figure in pixels

        Returns
        -------
        None, if show = True. A plotly.Figure object, otherwise.
        """
        raise NotImplementedError

    def copy(self):
        """
        make a copy of the object
        """
        raise NotImplementedError

    def describe(self, percentiles: list = []) -> pd.DataFrame:
        """
        provide descriptive statistics about the parameters in df.

        Parameters
        ----------
        percentiles: list
            a list of values in the [0, 1] range defining the desired percentiles
            to be calculated.

        Returns
        -------
        df: pd.DataFrame
            a pandas.DataFrame with the object descriptive statistics.
        """
        raise NotImplementedError

    def sampling_frequency(self, digits: float = 3) -> float:
        """
        return the "average" sampling frequency of the Point.
        """
        raise NotImplementedError

    def matches(self, obj) -> bool:
        """
        check if obj is "similar" to the actual object.
        """
        raise NotImplementedError

    def corr(self, obj) -> pd.DataFrame:
        """
        get the correlation between self and obj.

        Parameters
        ----------
        pnt: Any
            the object to be correlated with self.

        weighted: bool
            should the correlation be weighted by the number of non-missing data?
            True means that the correlation value is multiplied by the percentage
            of non-missing data in the sample.
            False, otherwise

        Returns
        -------
        r: pandas.DataFrame
            the correlation between self and pnt.
        """
        raise NotImplementedError

    def fillna(
        self,
        value: float = None,
        n_predictors: int = 3,
        predictors: list = [],
    ):
        """
        fill missing values in the point.

        Parameters
        ----------
        value: float or None
            the value to be used for missing data replacement.
            if None, cubic spline interpolation is used to extract the
            missing data.
            Please note that if predictors is not empty, this parameter is ignored.

        n_predictors: int
            the number of predictors to be used if predictors is not empty

        predictors: list
            list of objects that can be matched with self and that can be used to obtain
            missing coordinates via multiple linear regression.
            If left empty, cubic spline interpolation or constant value substitution is
            used according to the inputs provided in value.

        Returns
        -------
        filled: same class of self
            the object without missing data.
        """
        raise NotImplementedError


class _Indexer:
    """
    Wrapper of the pandas.DataFrame .loc/.iloc class object which allows the
    use of the .loc/.iloc operator on Vector and Segment objects.

    Parameters
    ----------
    attr: str
        the name of the attribute to which the indexer is mapped for.
        (e.g. "loc" or "iloc")

    obj: Vector, Segment
        the object instance whose attributes must be mapped to .(attr)

    attributes: keyworded objects
        list of named objects being the attributes pointing to loc.
    """

    def __init__(self, attr, obj, **attributes):
        """
        constructor
        """
        assert isinstance(attr, str), "'attr' must be a str instance."
        self.attr = attr
        txt = "obj must be a Vector or Segment instance."
        assert isinstance(obj, (Vector, Segment)), txt
        self.obj = obj
        self.attributes = {}
        for i, v in attributes.items():
            assert hasattr(obj, i), "The {} attribute is not part of obj.".format(i)
            self.attributes[i] = v

    def __setitem__(self, item, value):
        """
        set the items of all attributes of the object to value.

        Parameters
        ----------
        item: str
            the name of the item to be set.

        value: Any
            the value to be set on attr.
        """
        for i, v in self.attributes.items():
            if isinstance(value, self.obj.__class__):
                val = getattr(value, i).values
            else:
                val = value
            getattr(v, self.attr)[item] = val

    def __getitem__(self, item):
        """
        get the items of all attributes of the object to value.

        Parameters
        ----------
        item: str
            the name of the item to be returned.

        Returns
        -------
        obj: Vector, Segment
            the value associated to the requried item.
        """
        obj = self.obj.copy()
        for i, v in self.attributes.items():
            setattr(obj, i, getattr(v, self.attr)[item])
        return obj


class Point(pd.DataFrame, _AbstractObject):
    """
    Generate an object reflecting a dimension-less point
    in a n-dimensional space.

    Parameters
    ----------
    data: np.ndarray (structured or homogeneous), Iterable, dict, or DataFrame
        Dict can contain Series, arrays, constants, dataclass or list-like objects.
        If data is a dict, column order follows insertion-order.
        If a dict contains Series which have an index defined, it is aligned by its index.

    index: Index or array-like
        Index to use for resulting frame. Will default to RangeIndex if no indexing information
        part of input data and no index provided.

    columns: Index or array-like
        Column labels to use for resulting frame when data does not have them,
        defaulting to RangeIndex(0, 1, 2, â€¦, n). If data contains column labels, will
        perform column selection instead.

    dtype: dtype, default None
        Data type to force. Only a single dtype is allowed. If None, infer.

    copy: bool or None, default None
        Copy data from inputs. For dict data, the default of None behaves like copy=True.
        For DataFrame or 2d ndarray input, the default of None behaves like copy=False.
    """

    # * pandas.DataFrame overridden objects

    _cacher = ()

    dtype = np.float64

    def _set_as_cached(self, item, cacher) -> None:
        """
        Set the _cacher attribute on the calling object with a weakref to cacher.
        """
        self._cacher = (item, weakref.ref(cacher))

    @property
    def _constructor(self):
        return Point

    @property
    def _constructor_sliced(self):
        return Point

    @property
    def T(self):
        """
        return the transpose of the point
        """
        return Point(pd.DataFrame(self).T)

    # * _Object overridden methods

    def __str__(self) -> str:
        """
        convert self to a string.
        """
        return pd.DataFrame(self).__str__()

    def stack(self):
        """
        stack the Point as long format.
        """
        df = pd.DataFrame(self, copy=True)
        df.insert(0, "Time", df.index.to_numpy())
        df.index = pd.Index(range(df.shape[0]))
        return df.melt(
            id_vars="Time",
            value_vars=self.columns.tolist(),
            var_name="Dimension",
            value_name="Amplitude",
            ignore_index=True,
        )

    @staticmethod
    def unstack(df: pd.DataFrame):
        """
        generate a Point object from a stacked DataFrame.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            Point.stack() method.

        Returns
        -------

        point: Point
            the Point instance resulting from the dataframe reading.
        """
        out = df.pivot("Time", "Dimension")
        out.columns = pd.Index([i[1] for i in out.columns])
        out.index = pd.Index(out.index.to_numpy())
        return Point(out)

    def dropna(self):
        """
        return the Point without missing data.

        Returns
        -------
        full: Point
            the point without missing data.
        """
        return Point(pd.DataFrame(self).dropna(axis=0, inplace=False))

    def unique(self):
        """
        return the unique rows or columns in the point.

        Returns
        -------
        full: Point
            the point unique occurrences.
        """
        val, ix = np.unique(self.values, axis=0, return_index=True)
        idx = self.index.to_numpy()[ix]
        col = self.columns.to_numpy()
        return Point(val, index=idx, columns=col)

    def copy(self):
        """
        return a copy of the current point.
        """
        return Point(
            data=np.copy(self.values),
            index=np.copy(self.index.to_numpy()),
            columns=np.copy(self.columns.to_numpy()),
        )

    def plot(
        self,
        as_subplots: bool = False,
        lines: bool = True,
        show: bool = True,
        width: int = 1280,
        height: int = 720,
    ):
        """
        generate a plotly plot representing the current object.

        Parameters
        ----------
        as_subplots: bool (default=False)
            should the dimensions of Point be plotted as a single subplot?

        lines: bool (default=True)
            if True, only lines linking the samples are rendered. Otherwise,
            a scatter plot is rendered.

        show: bool (default=True)
            if True the generated figure is immediately plotted. Otherwise the
            generated object is returned

        width: int (default=1280)
            the width of the output figure in pixels

        height: int (default=720)
            the height of the output figure in pixels

        Returns
        -------
        None, if show = True. A plotly.Figure object, otherwise.
        """
        fun = px.line if lines else px.scatter
        fig = fun(
            data_frame=self.stack(),
            x="Time",
            y="Amplitude",
            color="Dimension",
            facet_row="Dimension" if as_subplots else None,
            width=width,
            height=height,
            template="simple_white",
        )
        fig.update_layout(showlegend=not as_subplots)
        if show:
            fig.show()
        else:
            return fig

    def describe(self, percentiles: list = []) -> pd.DataFrame:
        """
        provide descriptive statistics about the parameters in df.

        Parameters
        ----------
        percentiles: list
            a list of values in the [0, 1] range defining the desired percentiles
            to be calculated.

        Returns
        -------
        df: pd.DataFrame
            a pandas.DataFrame with the object descriptive statistics.
        """
        df = self.stack().drop("Time", axis=1)
        df = df.groupby(["Dimension"]).describe(percentiles=percentiles)
        df.columns = pd.Index([i[0] for i in df.columns])
        return df

    @property
    def sampling_frequency(self) -> float:
        """
        return the "average" sampling frequency of the Point.
        """
        return float(1.0 / np.mean(np.diff(self.index.to_numpy())))

    def matches(self, obj) -> bool:
        """
        check if the object is similar to self.

        Parameters
        ----------
        object:  Any
            the object to be compared

        Returns
        -------
        Q: bool
            true if obj matches self, False otherwise.
        """

        def check_shape(obj):
            """
            check the shape is equal between self and obj.
            """
            a_rows, a_cols = self.shape
            b_rows, b_cols = obj.shape
            return a_rows == b_rows and a_cols == b_cols

        def check_columns(obj):
            """
            check the columns are the same between self and obj.
            """
            a_cols = self.columns.to_numpy()
            b_cols = obj.columns.to_numpy()
            return all([i in b_cols for i in a_cols])

        def check_indices(obj):
            """
            check the indices are the same between self and obj.
            """
            a_idxs = self.index.to_numpy()
            b_idxs = obj.index.to_numpy()
            return all([i in b_idxs for i in a_idxs])

        if isinstance(obj, np.ndarray):
            return check_shape(obj)
        elif isinstance(obj, (Point, pd.DataFrame)):
            return check_shape(obj) and check_columns(obj) and check_indices(obj)
        elif isinstance(obj, Vector):
            pnt = obj.amplitude
            return check_shape(pnt) and check_columns(pnt) and check_indices(pnt)
        elif isinstance(obj, Segment):
            pnt = obj.p0
            return check_shape(pnt) and check_columns(pnt) and check_indices(pnt)
        return False

    def corr(self, obj, weighted=True):
        """
        get the correlation between self and obj.

        Parameters
        ----------
        obj: numpy.ndarray, pandas.DataFrame, Point, Vector, Segment
            the point to be correlated with self.

        weighted: bool
            should the correlation be weighted by the number of non-missing data?
            True means that the correlation value is multiplied by the percentage
            of non-missing data in the sample.
            False, otherwise

        Returns
        -------
        r: pandas.DataFrame
            the correlation between self and obj.
        """
        assert self.matches(obj), "'obj' must be matchable with self."
        a = self.copy()
        a.columns = pd.MultiIndex.from_tuples([("Self", "", i) for i in a])
        if isinstance(obj, np.ndarray):
            cols = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
            b = pd.DataFrame(obj, index=self.index, columns=cols)
        elif isinstance(obj, (pd.DataFrame, Point)):
            b = obj.copy()
            b.columns = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
        elif isinstance(obj, (Vector, Segment)):
            b = obj.pivot()
            b.columns = pd.MultiIndex.from_tuples([("Obj", *i) for i in b])
        else:
            txt = [i.__class__.__name__ for i in [self, obj]]
            txt = "correlation between {} and {} is not supported.".format(*txt)
            raise NotImplementedError(txt)
        df = pd.DataFrame(pd.concat([a, b], axis=1))
        dfn = df.dropna(inplace=False)
        r = df.corr().iloc[: a.shape[1], b.shape[1] :]  # pearson's correlation
        if weighted:
            r *= dfn.shape[0] / df.shape[0]
        return r

    def fillna(
        self,
        value: float = None,
        n_predictors: int = 3,
        predictors: list = [],
    ):
        """
        fill missing values in the point.

        Parameters
        ----------
        value: float or None
            the value to be used for missing data replacement.
            if None, cubic spline interpolation is used to extract the
            missing data.
            Please note that if predictors is not empty, this parameter is ignored.

        n_predictors: int
            the number of predictors to be used if predictors is not empty

        predictors: list
            list of Vectors that can be matched with self and that can be used to obtain
            missing coordinates via multiple linear regression.
            If left empty, cubic spline interpolation or constant value substitution is
            used according to the inputs provided in value.

        Returns
        -------
        filled: Point
            the point without missing data.
        """
        # check if missing values exist
        miss = self.isna().any(1).values.flatten()
        filled = self.copy()

        # otherwise return a copy of the actual point
        if not np.any(miss):
            return filled

        # get the point index
        x_new = filled.index.to_numpy()

        # multiple linear regression
        assert isinstance(predictors, list), "'predictors' must be a 'list'."
        if len(predictors) > 0:
            assert isinstance(n_predictors, int), "'n_predictors' must be an 'int'."

            # get mean absolute correlation between self and the predictors
            corrs = [np.mean(abs(self.corr(i).values)) for i in predictors]

            # keep the best n_predictors
            best_preds = np.argsort(corrs)[::-1][:n_predictors]
            best_preds = [v for i, v in enumerate(predictors) if i in best_preds]
            x = pd.concat(best_preds, axis=1).values

            # get the predictive equation
            y = filled.values
            valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
            lr = LinearRegression(y[valid], x[valid], True)

            # replace missing values
            filled.loc[miss, filled.columns] = lr.predict(x[miss]).values

        # fill by cubic spline interpolation
        elif value is None:
            df_old = self.dropna()
            for i in filled.columns:
                y_new = interpolate_cs(
                    y=df_old[i].values.flatten(),
                    x_old=df_old.index.to_numpy(),
                    x_new=x_new,
                )
                filled.loc[x_new, [i]] = np.atleast_2d(y_new).T

        # constant value
        else:
            vals = filled.values
            nans = np.argwhere(np.isnan(vals))
            vals[nans] = value
            filled.loc[x_new, filled.columns] = vals

        return filled

    # * Point unique methods

    def __init__(self, *args, **kwargs):
        if any([i == "name" for i in kwargs]):
            args = [pd.Series(*args, **kwargs)]
            kwargs = {}
        super(Point, self).__init__(*args, **kwargs)

    @property
    def norm(self):
        """
        get the norm of the point.
        """
        dt = np.sqrt(np.sum(self.values ** 2, axis=1))
        lbls = [str(i) for i in self.columns.to_list()]
        cols = "|{}|".format("+".join(lbls))
        idx = self.index
        return Point(data=dt, columns=[cols], index=idx)

    def get_angle(self, x: str, y: str, name: str = None):
        """
        return the angle between dimensions y and x using the arctan function.

        Parameters
        ----------
        x, y: str
            the name of the columns to be used for the angle calculation.

        name: str or None
            the name of the output dataframe column

        Returns
        -------
        q: Point
            the angle in radiants.
        """

        # check the data
        if name is None:
            name = "Angle"
        assert isinstance(name, str), "name must be a string"
        assert isinstance(x, str), "x must be a string"
        assert x in self.columns.to_list(), "x not in columns."
        assert isinstance(y, str), "y must be a string"
        assert y in self.columns.to_list(), "y not in columns."

        # calculate the angle
        q = np.arctan2(self[y].values.flatten(), self[x].values.flatten())
        return Point(q, columns=[name], index=self.index)

    def __radd__(self, obj):
        """
        right addition.
        """
        return self + obj

    def __rsub__(self, obj):
        """
        right subtraction.
        """
        return -self + obj

    def __rmul__(self, obj):
        """
        right multiplication.
        """
        return self * obj

    def __rtruediv__(self, obj):
        """
        right division.
        """

        return obj * (self ** (-1))


class Vector(_AbstractObject):
    """
    Generate an object reflecting a dimension-less vector in a n-dimensional space.

    Parameters
    ----------

    amplitude_data: Point, pandas.DataFrame, numpy.ndarray, list
        the amplitude of the vector.

    origin_data: Point, pandas.DataFrame, numpy.ndarray, list
        the origin of the vector.

    index: arraylike
        the index for both the amplitude and origin of the vector.

    columns: arraylike
        the name of the dimensions of the vector's origin and amplitude.
    """

    # * _Object implemented methods

    def __str__(self) -> str:
        """
        convert self to a string.
        """
        return self.pivot().__str__()

    def stack(self) -> pd.DataFrame:
        """
        stack the object as a long format DataFrame.
        """
        a = self.amplitude.stack()
        a.insert(0, "Source", np.tile("Amplitude", a.shape[0]))
        o = self.origin.stack()
        o.insert(0, "Source", np.tile("Origin", o.shape[0]))
        return pd.concat([a, o], axis=0, ignore_index=True)

    @staticmethod
    def unstack(df: pd.DataFrame):
        """
        convert a long format DataFrame into an instance of the object.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            _Object.stack() method.

        Returns
        -------

        vector: Vector
            the Vector instance resulting from the dataframe reading.
        """
        cols = ["Time", "Dimension", "Amplitude"]
        amp = Point.unstack(df.loc[df.isin(["Amplitude"]).any(1)][cols])
        ori = Point.unstack(df.loc[df.isin(["Origin"]).any(1)][cols])
        return Vector(amplitude_data=amp, origin_data=ori)

    def dropna(self):
        """
        return the Vector without missing data.

        Returns
        -------
        full: Vector
            the vector without missing data.
        """
        i = self.pivot().dropna().index.to_numpy()
        return Vector(
            amplitude_data=self.amplitude.loc[i].copy(),
            origin_data=self.origin.loc[i].copy(),
        )

    def unique(self):
        """
        return the unique samples of the vector.

        Returns
        -------
        full: Vector
            the vector unique occurrences.
        """
        i = np.unique(self.pivot().values, axis=0, return_index=True)[1]
        return Vector(
            amplitude_data=self.amplitude.iloc[i].copy(),
            origin_data=self.origin.iloc[i].copy(),
        )

    def copy(self):
        """
        return a copy of the current vector.
        """
        return Vector(
            amplitude_data=self.amplitude.copy(),
            origin_data=self.origin.copy(),
        )

    def plot(
        self,
        as_subplots: bool = False,
        lines: bool = True,
        show: bool = True,
        width: int = 1280,
        height: int = 720,
    ):
        """
        generate a plotly plot representing the current object.

        Parameters
        ----------
        as_subplots: bool (default=False)
            should the dimensions of Point be plotted as a single subplot?

        lines: bool (default=True)
            if True, only lines linking the samples are rendered. Otherwise,
            a scatter plot is rendered.

        show: bool (default=True)
            if True the generated figure is immediately plotted. Otherwise the
            generated object is returned

        width: int (default=1280)
            the width of the output figure in pixels

        height: int (default=720)
            the height of the output figure in pixels

        Returns
        -------
        None, if show = True. A plotly.Figure object, otherwise.
        """
        fun = px.line if lines else px.scatter
        fig = fun(
            data_frame=self.stack(),
            x="Time",
            y="Amplitude",
            color="Dimension",
            facet_row="Dimension" if as_subplots else None,
            facet_col="Source",
            width=width,
            height=height,
            template="simple_white",
        )
        fig.update_layout(showlegend=not as_subplots)
        if show:
            fig.show()
        else:
            return fig

    def describe(self, percentiles: list = []):
        """
        provide descriptive statistics about the parameters in df.

        Parameters
        ----------
        percentiles: list
            a list of values in the [0, 1] range defining the desired percentiles
            to be calculated.

        Returns
        -------
        df: pd.DataFrame
            a pandas.DataFrame with the object descriptive statistics.
        """
        grp = self.stack().drop("Time", axis=1).groupby(["Source", "Dimension"])
        df = grp.describe(percentiles=percentiles)
        df.columns = pd.Index([i[1] for i in df.columns])
        return df

    @property
    def sampling_frequency(self) -> float:
        """
        return the "average" sampling frequency of the Vector.

        Parameters
        ----------
        digits: int
            the number of digits for the returing value
        """
        return self.amplitude.sampling_frequency

    def matches(self, obj) -> bool:
        """
        check if obj is comparable to self.

        Parameters
        ----------
        obj: Any
            the object to be compared

        Returns
        -------
        Q: bool
            true if obj matches self, False otherwise.
        """
        if isinstance(obj, Vector):
            return self.amplitude.matches(obj.amplitude)
        elif isinstance(obj, Segment):
            return self.amplitude.matches(obj.p0)
        elif isinstance(obj, (pd.DataFrame, Point, np.ndarray)):
            return self.amplitude.matches(obj)
        return False

    def corr(self, obj, weighted=True):
        """
        get the correlation between self and obj.

        Parameters
        ----------
        obj: numpy.ndarray, pandas.DataFrame, Point, Vector, Segment
            the point to be correlated with self.

        weighted: bool
            should the correlation be weighted by the number of non-missing data?
            True means that the correlation value is multiplied by the percentage
            of non-missing data in the sample.
            False, otherwise

        Returns
        -------
        r: pandas.DataFrame
            the correlation between self and obj.
        """
        assert self.matches(obj), "'obj' must be matchable with self."
        a = self.pivot()
        a.columns = pd.MultiIndex.from_tuples([("Self", *i) for i in a])
        if isinstance(obj, np.ndarray):
            cols = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
            b = pd.DataFrame(obj, index=self.index, columns=cols)
        elif isinstance(obj, (pd.DataFrame, Point)):
            b = obj.copy()
            b.columns = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
        elif isinstance(obj, (Vector, Segment)):
            b = obj.pivot()
            b.columns = pd.MultiIndex.from_tuples([("Obj", *i) for i in b])
        else:
            txt = [i.__class__.__name__ for i in [self, obj]]
            txt = "correlation between {} and {} is not supported.".format(*txt)
            raise NotImplementedError(txt)
        df = pd.DataFrame(pd.concat([a, b], axis=1))
        dfn = df.dropna(inplace=False)
        r = df.corr().iloc[: a.shape[1], b.shape[1] :]  # pearson's correlation
        if weighted:
            r *= dfn.shape[0] / df.shape[0]
        return r

    def fillna(
        self,
        value: float = None,
        n_predictors: int = 3,
        predictors: list = [],
    ):
        """
        fill missing values in the vector.

        Parameters
        ----------
        value: float or None
            the value to be used for missing data replacement.
            if None, cubic spline interpolation is used to extract the
            missing data.
            Please note that if predictors is not empty, this parameter is ignored.

        n_predictors: int
            the number of predictors to be used if predictors is not empty

        predictors: list
            list of Vectors that can be matched with self and that can be used to obtain
            missing coordinates via multiple linear regression.
            If left empty, cubic spline interpolation or constant value substitution is
            used according to the inputs provided in value.

        Returns
        -------
        filled: Vector
            the vector without missing data.
        """
        # check if missing values exist
        miss = self.pivot().isna().any(1).values.flatten()
        filled = self.copy()

        # otherwise return a copy of the actual vector
        if not np.any(miss):
            return filled

        # get the index
        x_new = filled.amplitude.index.to_numpy()

        # multiple linear regression
        assert isinstance(predictors, list), "'predictors' must be a 'list'."
        if len(predictors) > 0:
            assert isinstance(n_predictors, int), "'n_predictors' must be an 'int'."

            # get mean absolute correlation between self and the predictors
            corrs = [np.mean(abs(self.corr(i).values)) for i in predictors]

            # keep the best n_predictors
            best_preds = np.argsort(corrs)[::-1][:n_predictors]
            best_preds = [v for i, v in enumerate(predictors) if i in best_preds]
            x = pd.concat(best_preds, axis=1).values

            # get the predictive equation
            y = self.pivot().values
            valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
            lr = LinearRegression(y[valid], x[valid], True)

            # get the predictive equation
            valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
            lr = LinearRegression(y[valid], x[valid], True)

            # replace missing values
            vals = lr.predict(x[miss]).values
            cols = filled.amplitude.columns.tolist()
            filled.amplitude.loc[miss, cols] = vals[:, : len(cols)]
            filled.origin.loc[miss, cols] = vals[:, len(cols) :]

        # fill by cubic spline interpolation
        elif value is None:
            v_old = self.dropna()
            for i in filled.amplitude.columns:

                # amplitude
                a_new = interpolate_cs(
                    y=v_old.amplitude[i].values.flatten(),
                    x_old=v_old.amplitude.index.to_numpy(),
                    x_new=x_new,
                )
                filled.amplitude.loc[x_new, [i]] = np.atleast_2d(a_new).T

                # origin
                o_new = interpolate_cs(
                    y=v_old.origin[i].values.flatten(),
                    x_old=v_old.amplitude.index.to_numpy(),
                    x_new=x_new,
                )
                filled.origin.loc[x_new, [i]] = np.atleast_2d(o_new).T

        # constant value
        else:
            cols = filled.amplitude.columns.tolist()
            av = filled.amplitude.values
            nans = np.argwhere(np.isnan(av))
            av[nans] = value
            filled.amplitude.loc[x_new, cols] = av
            ov = filled.origin.values
            nans = np.argwhere(np.isnan(ov))
            ov[nans] = value
            filled.amplitude.loc[x_new, cols] = ov

        return filled

    # * Vector class methods

    @property
    def index(self):
        """
        the index of the vector.

        Returns
        -------
        out: list
            the list containing the indices of the vector.
        """
        return self.amplitude.index.to_list()

    @property
    def columns(self):
        """
        the dimensions labels of the vector.

        Returns
        -------
        out: list
            the list containing the dimensions' labels of the vector.
        """
        return self.amplitude.columns.to_numpy()

    @property
    def shape(self):
        """
        the shape of the vector
        """
        return self.amplitude.shape

    @property
    def ndim(self):
        """
        the number of dimensions of the vector
        """
        return self.amplitude.shape[1]

    @property
    def nsamp(self):
        """
        the numbre of samples of the vector
        """
        return self.amplitude.shape[0]

    @property
    def norm(self) -> Point:
        """
        get the norm of the vector.
        """
        return (self.amplitude - self.origin).norm

    @property
    def T(self):
        """
        return the transpose of the vector
        """
        return Vector(
            amplitude_data=self.amplitude.T,
            origin_data=self.origin.T,
        )

    def __len__(self):
        """
        the length of the vector
        """
        return self.amplitude.shape[0]

    def _adjust_indices(self, idx: Tuple[list, np.ndarray]) -> np.ndarray:
        """
        adjust the input index or columns to be used for creating a vector.

        Parameters
        ----------
        idx: list, numpy.ndarray
            a 1D list to be arranged properly for generating a Vector.

        Returns
        -------
        out: numpy.ndarray
            a 1D numpy.ndarray to be used for the generation of the Vector.
        """
        if isinstance(idx, list):
            out = np.array(idx)
        else:
            out = idx
        assert out.ndim < 2, "'array' must be a 1D array."
        return out

    def _get_data(
        self,
        data: Tuple[list, np.ndarray, pd.DataFrame, Point],
        index: Tuple[list, np.ndarray],
        columns: Tuple[list, np.ndarray],
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        get the input index or columns to be used for creating a vector.

        Parameters
        ----------
        data: np.ndarray
            the data for the amplitude or the origin of the vector.

        idx: numpy.ndarray
            a 1D array to be arranged properly for generating a Vector.

        Returns
        -------
        out: numpy.ndarray
            a 1D numpy.ndarray to be used for the generation of the Vector.
        """
        if isinstance(data, Point):
            out = data
        elif isinstance(data, pd.DataFrame):
            out = Point(data)
        else:

            # check the data
            if isinstance(data, list):
                val = np.array(data)
            elif isinstance(data, np.ndarray):
                val = data
            else:
                txt = "amplitude_data and origin_data must be an instance of "
                txt += "[List, numpy.ndarray, pandas.DataFrame, Point]."
                raise ValueError(txt)
            if val.ndim == 1:
                val = np.atleast_2d(val).T
            elif val.ndim > 2:
                txt = "amplitude_data and origin_data must be a 1D or 2D array."
                raise ValueError(txt)

            # check the index
            if index is None:
                idx = np.arange(data.shape[0])
            else:
                idx = self._adjust_indices(index)
            txt = "index has length {}, but it should be {}."
            txt = txt.format(len(idx), val.shape[0])
            assert len(idx) == val.shape[0], txt

            # check the columns
            if columns is None:
                col = np.array(["D{}".format(i + 1) for i in range(data.shape[1])])
            else:
                col = self._adjust_indices(columns)
            txt = "columns has length {}, but it should be {}."
            txt = txt.format(len(col), val.shape[1])
            assert len(col) == val.shape[1], txt

            # generate the Point object
            out = Point(data=val, index=idx, columns=col)

        return out

    def __init__(
        self,
        amplitude_data: Tuple[Point, pd.DataFrame, np.ndarray, list],
        origin_data: Tuple[Point, pd.DataFrame, np.ndarray, list] = None,
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
    ):
        # get amplitude_data and origin_data as Point instances.
        amp = self._get_data(amplitude_data, index, columns)
        if origin_data is None:
            ori = amp * 0
        else:
            ori = self._get_data(origin_data, index, columns)

        # check amplitude and origin matches with each other
        txt = "amplitude_data and origin_data must have the same shape."
        assert amp.matches(ori), txt

        # create the vector
        self.amplitude = amp
        self.origin = ori

        # set the indexers .loc and .iloc
        self.loc = _Indexer(
            attr="loc",
            obj=self,
            amplitude=self.amplitude,
            origin=self.origin,
        )
        self.iloc = _Indexer(
            attr="iloc",
            obj=self,
            amplitude=self.amplitude,
            origin=self.origin,
        )

    def _get_item(self, item):
        """
        ensure that item is an iterable object.

        Parameters
        ----------
        item: Any
            the item attribute passed to __setitem__ or __getitem__.

        Returns
        -------
        itm: iterable
            an iterable version of item.
        """
        if isinstance(item, str) or not hasattr(item, "__iter__"):
            return [item]
        else:
            return item

    def __setitem__(self, item, value):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        value: any
            the value to be set for the provided item.
        """
        itm = self._get_item(item)

        try:
            self.loc.__setitem__(itm, value)
        except KeyError:
            try:
                self.loc.__setitem__(np.s_[:, itm], value)
            except (IndexError, AttributeError):
                try:
                    self.iloc.__setitem__(itm, value)
                except KeyError:
                    self.iloc.__setitem__(np.s_[:, itm], value)
        except (IndexError, AttributeError):
            try:
                self.iloc.__setitem__(itm, value)
            except KeyError:
                self.iloc.__setitem__(np.s_[:, itm], value)

    def __getitem__(self, item):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        Returns
        -------
        val: Vector
            the (sliced) vector.
        """
        itm = self._get_item(item)

        try:
            return self.loc.__getitem__(itm)
        except KeyError:
            try:
                return self.loc.__getitem__(np.s_[:, itm])
            except (ValueError, TypeError):
                try:
                    return self.iloc.__getitem__(itm)
                except KeyError:
                    return self.iloc.__getitem__(np.s_[:, itm])
        except (ValueError, TypeError):
            try:
                return self.iloc.__getitem__(itm)
            except KeyError:
                return self.iloc.__getitem__(np.s_[:, itm])

    def pivot(self) -> pd.DataFrame:
        """
        generate a wide dataframe object containing both origin and amplitudes.
        """
        df = self.stack().pivot("Time", ["Source", "Dimension"])
        df.columns = pd.Index([i[1:] for i in df.columns])
        return df

    def get_angle(self, x: str, y: str, name: str = None) -> Point:
        """
        return the angle between dimensions y and x using the arctan function.

        Parameters
        ----------
        x, y: str
            the name of the columns to be used for the angle calculation.

        name: str or None
            the name of the output dataframe column

        Returns
        -------
        q: Point
            the angle in radiants.
        """
        return (self.amplitude - self.origin).get_angle(x, y, name)

    def __iadd__(self, obj):
        """
        iterative addition.
        """
        self = self + obj
        return self

    def __radd__(self, obj):
        """
        right addition.
        """
        return self + obj

    def __add__(self, obj):
        """
        addition.
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude + val,
            origin_data=self.origin,
        )

    def __isub__(self, obj):
        """
        iterative subtraction.
        """
        self = self - obj
        return self

    def __rsub__(self, obj):
        """
        right subtraction.
        """
        return -self + obj

    def __sub__(self, obj):
        """
        subtraction.
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude - val,
            origin_data=self.origin,
        )

    def __imul__(self, obj):
        """
        iterative multiplication.
        """
        self = self * obj
        return self

    def __rmul__(self, obj):
        """
        right multiplication.
        """
        return self * obj

    def __mul__(self, obj):
        """
        multiplication
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude * val,
            origin_data=self.origin,
        )

    def __itruediv__(self, obj):
        """
        iterative division.
        """
        self = self / obj
        return self

    def __rtruediv__(self, obj):
        """
        iterative division.
        """

        return obj * (self ** (-1))

    def __truediv__(self, obj):
        """
        division
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude / val,
            origin_data=self.origin,
        )

    def __ifloordiv__(self, obj):
        """
        iterative floor division.
        """
        self = self / obj
        return self

    def __floordiv__(self, obj):
        """
        floor division
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude // val,
            origin_data=self.origin,
        )

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude ** val,
            origin_data=self.origin,
        )

    def __abs__(self):
        """
        absolute value
        """
        return Vector(abs(self.amplitude), self.origin)

    def __mod__(self, obj):
        """
        module (% operator).
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude % val,
            origin_data=self.origin,
        )

    def __neg__(self):
        """
        negative of self (- operator).
        """
        return self * (-1)

    def __pos__(self):
        """
        positive of self (+ operator).
        """
        return self * (1)

    def __truth__(self):
        """
        truth (identity) operator.
        """
        return self

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        if isinstance(obj, Vector):
            val = obj.amplitude
        else:
            val = obj
        return Vector(
            amplitude_data=self.amplitude @ val,
            origin_data=self.origin @ val,
        )


class Segment(_AbstractObject):
    """
    Generate an object reflecting a dimension-less vector in a n-dimensional space.

    Parameters
    ----------

        p0_data: Point, pandas.DataFrame, numpy.ndarray, list
        the first point data of the segment.

    p1_data: Point, pandas.DataFrame, numpy.ndarray, list
        the second of the segment.

    index: arraylike
        the index for both the amplitude and origin of the segment.

    columns: arraylike
        the name of the dimensions of the segment's points.
    """

    # * _Object implemented methods

    def __str__(self) -> str:
        """
        convert self to a string.
        """
        return self.pivot().__str__()

    def stack(self) -> pd.DataFrame:
        """
        stack the object as a long format DataFrame.
        """
        a = self.p0.stack()
        a.insert(0, "Source", np.tile("P0", a.shape[0]))
        o = self.p1.stack()
        o.insert(0, "Source", np.tile("P1", o.shape[0]))
        return pd.concat([a, o], axis=0, ignore_index=True)

    @staticmethod
    def unstack(df: pd.DataFrame):
        """
        convert a long format DataFrame into an instance of the object.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            _Object.stack() method.

        Returns
        -------

        seg: Segment
            the Segment instance resulting from the dataframe reading.
        """
        cols = ["Time", "Dimension", "Amplitude"]
        return Segment(
            p0_data=Point.unstack(df.loc[df.isin(["P0"]).any(1)][cols]),
            p1_data=Point.unstack(df.loc[df.isin(["P1"]).any(1)][cols]),
        )

    def dropna(self):
        """
        return the Segment without missing data.

        Returns
        -------
        full: Segment
            the segment without missing data.
        """
        i = self.pivot().dropna().index.to_numpy()
        return Segment(
            p0_data=self.p0.loc[i].copy(),
            p1_data=self.p1.loc[i].copy(),
        )

    def unique(self):
        """
        return the unique samples of the segment.

        Returns
        -------
        full: Segment
            the segment unique occurrences.
        """
        i = np.unique(self.pivot().values, axis=0, return_index=True)[1]
        return Segment(
            p0_data=self.p0.loc[i].copy(),
            p1_data=self.p1.loc[i].copy(),
        )

    def copy(self):
        """
        return a copy of the current segment.
        """
        return Segment(p0_data=self.p0.copy(), p1_data=self.p1.copy())

    def plot(
        self,
        as_subplots: bool = False,
        lines: bool = True,
        show: bool = True,
        width: int = 1280,
        height: int = 720,
    ):
        """
        generate a plotly plot representing the current object.

        Parameters
        ----------
        as_subplots: bool (default=False)
            should the dimensions of Point be plotted as a single subplot?

        lines: bool (default=True)
            if True, only lines linking the samples are rendered. Otherwise,
            a scatter plot is rendered.

        show: bool (default=True)
            if True the generated figure is immediately plotted. Otherwise the
            generated object is returned

        width: int (default=1280)
            the width of the output figure in pixels

        height: int (default=720)
            the height of the output figure in pixels

        Returns
        -------
        None, if show = True. A plotly.Figure object, otherwise.
        """
        fun = px.line if lines else px.scatter
        fig = fun(
            data_frame=self.stack(),
            x="Time",
            y="Amplitude",
            color="Dimension",
            facet_row="Dimension" if as_subplots else None,
            facet_col="Source",
            width=width,
            height=height,
            template="simple_white",
        )
        fig.update_layout(showlegend=not as_subplots)
        if show:
            fig.show()
        else:
            return fig

    def describe(self, percentiles: list = []):
        """
        provide descriptive statistics about self.

        Parameters
        ----------
        percentiles: list
            a list of values in the [0, 1] range defining the desired percentiles
            to be calculated.

        Returns
        -------
        df: pd.DataFrame
            a pandas.DataFrame with the object descriptive statistics.
        """
        grp = self.stack().drop("Time", axis=1).groupby(["Source", "Dimension"])
        df = grp.describe(percentiles=percentiles)
        df.columns = pd.Index([i[1] for i in df.columns])
        return df

    @property
    def sampling_frequency(self) -> float:
        """
        return the "average" sampling frequency of the Segment.

        Parameters
        ----------
        digits: int
            the number of digits for the returing value
        """
        return self.p0.sampling_frequency

    def matches(self, obj) -> bool:
        """
        check if obj is comparable to self.

        Parameters
        ----------
        obj: Any
            the object to be compared

        Returns
        -------
        Q: bool
            true if obj matches self, False otherwise.
        """
        if isinstance(obj, Vector):
            return self.amplitude.matches(obj.amplitude)
        elif isinstance(obj, Segment):
            return self.amplitude.matches(obj.p0)
        elif isinstance(obj, (pd.DataFrame, Point, np.ndarray)):
            return self.amplitude.matches(obj)
        return False

    def corr(self, obj, weighted=True):
        """
        get the correlation between self and obj.

        Parameters
        ----------
        obj: numpy.ndarray, pandas.DataFrame, Point, Vector, Segment
            the point to be correlated with self.

        weighted: bool
            should the correlation be weighted by the number of non-missing data?
            True means that the correlation value is multiplied by the percentage
            of non-missing data in the sample.
            False, otherwise

        Returns
        -------
        r: pandas.DataFrame
            the correlation between self and obj.
        """
        assert self.matches(obj), "'obj' must be matchable with self."
        a = self.pivot()
        a.columns = pd.MultiIndex.from_tuples([("Self", *i) for i in a])
        if isinstance(obj, np.ndarray):
            cols = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
            b = pd.DataFrame(obj, index=self.index, columns=cols)
        elif isinstance(obj, (pd.DataFrame, Point)):
            b = obj.copy()
            b.columns = pd.MultiIndex.from_tuples([("Obj", "", i) for i in self])
        elif isinstance(obj, (Vector, Segment)):
            b = obj.pivot()
            b.columns = pd.MultiIndex.from_tuples([("Obj", *i) for i in b])
        else:
            txt = [i.__class__.__name__ for i in [self, obj]]
            txt = "correlation between {} and {} is not supported.".format(*txt)
            raise NotImplementedError(txt)
        df = pd.DataFrame(pd.concat([a, b], axis=1))
        dfn = df.dropna(inplace=False)
        r = df.corr().iloc[: a.shape[1], b.shape[1] :]  # pearson's correlation
        if weighted:
            r *= dfn.shape[0] / df.shape[0]
        return r

    def fillna(
        self,
        value: float = None,
        n_predictors: int = 3,
        predictors: list = [],
    ):
        """
        fill missing values in the vector.

        Parameters
        ----------
        value: float or None
            the value to be used for missing data replacement.
            if None, cubic spline interpolation is used to extract the
            missing data.
            Please note that if predictors is not empty, this parameter is ignored.

        n_predictors: int
            the number of predictors to be used if predictors is not empty

        predictors: list
            list of Vectors that can be matched with self and that can be used to obtain
            missing coordinates via multiple linear regression.
            If left empty, cubic spline interpolation or constant value substitution is
            used according to the inputs provided in value.

        Returns
        -------
        filled: Vector
            the vector without missing data.
        """
        # check if missing values exist
        miss = self.pivot().isna().any(1).values.flatten()
        filled = self.copy()

        # otherwise return a copy of the actual vector
        if not np.any(miss):
            return filled

        # get the index
        x_new = filled.amplitude.index.to_numpy()

        # multiple linear regression
        assert isinstance(predictors, list), "'predictors' must be a 'list'."
        if len(predictors) > 0:
            assert isinstance(n_predictors, int), "'n_predictors' must be an 'int'."

            # get mean absolute correlation between self and the predictors
            corrs = [np.mean(abs(self.corr(i).values)) for i in predictors]

            # keep the best n_predictors
            best_preds = np.argsort(corrs)[::-1][:n_predictors]
            best_preds = [v for i, v in enumerate(predictors) if i in best_preds]
            x = pd.concat(best_preds, axis=1).values

            # get the predictive equation
            y = self.pivot().values
            valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
            lr = LinearRegression(y[valid], x[valid], True)

            # get the predictive equation
            valid = np.all(~np.isnan(np.concatenate([y, x], axis=1)), axis=1)
            lr = LinearRegression(y[valid], x[valid], True)

            # replace missing values
            vals = lr.predict(x[miss]).values
            cols = filled.p0.columns.tolist()
            filled.p0.loc[miss, cols] = vals[:, : len(cols)]
            filled.p1.loc[miss, cols] = vals[:, len(cols) :]

        # fill by cubic spline interpolation
        elif value is None:
            v_old = self.dropna()
            for i in filled.amplitude.columns:

                # amplitude
                a_new = interpolate_cs(
                    y=v_old.amplitude[i].values.flatten(),
                    x_old=v_old.amplitude.index.to_numpy(),
                    x_new=x_new,
                )
                filled.amplitude.loc[x_new, [i]] = np.atleast_2d(a_new).T

                # origin
                o_new = interpolate_cs(
                    y=v_old.origin[i].values.flatten(),
                    x_old=v_old.amplitude.index.to_numpy(),
                    x_new=x_new,
                )
                filled.origin.loc[x_new, [i]] = np.atleast_2d(o_new).T

        # constant value
        else:
            cols = filled.amplitude.columns.tolist()
            av = filled.amplitude.values
            nans = np.argwhere(np.isnan(av))
            av[nans] = value
            filled.amplitude.loc[x_new, cols] = av
            ov = filled.origin.values
            nans = np.argwhere(np.isnan(ov))
            ov[nans] = value
            filled.amplitude.loc[x_new, cols] = ov

        return filled

    # * Vector class methods

    @property
    def index(self):
        """
        the index of the vector.

        Returns
        -------
        out: list
            the list containing the indices of the vector.
        """
        return self.p0.index.to_list()

    @property
    def columns(self):
        """
        the dimensions labels of the vector.

        Returns
        -------
        out: list
            the list containing the dimensions' labels of the vector.
        """
        return self.p0.columns.to_numpy()

    @property
    def shape(self):
        """
        the shape of the vector
        """
        return self.p0.shape

    @property
    def ndim(self):
        """
        the number of dimensions of the vector
        """
        return self.p0.shape[1]

    @property
    def nsamp(self):
        """
        the numbre of samples of the vector
        """
        return self.p0.shape[0]

    @property
    def norm(self) -> Point:
        """
        get the norm of the vector.
        """
        return (self.p1 - self.p0).norm

    @property
    def T(self):
        """
        return the transpose of the vector
        """
        return Segment(p0_data=self.p0.T, p1_data=self.p0.T)

    def __len__(self):
        """
        the length of the vector
        """
        return self.p0.shape[0]

    def _adjust_indices(self, idx: Tuple[list, np.ndarray]) -> np.ndarray:
        """
        adjust the input index or columns to be used for creating a segment.

        Parameters
        ----------
        idx: list, numpy.ndarray
            a 1D list to be arranged properly for generating a Vector.

        Returns
        -------
        out: numpy.ndarray
            a 1D numpy.ndarray to be used for the generation of the Vector.
        """
        if isinstance(idx, list):
            out = np.array(idx)
        else:
            out = idx
        assert out.ndim < 2, "'array' must be a 1D array."
        return out

    def _get_data(
        self,
        data: Tuple[list, np.ndarray, pd.DataFrame, Point],
        index: Tuple[list, np.ndarray],
        columns: Tuple[list, np.ndarray],
    ) -> Tuple[np.ndarray, np.ndarray]:
        """
        get the input index or columns to be used for creating a Segment.

        Parameters
        ----------
        data: np.ndarray
            the data for the amplitude or the origin of the segment.

        idx: numpy.ndarray
            a 1D array to be arranged properly for generating a segment.

        Returns
        -------
        out: numpy.ndarray
            a 1D numpy.ndarray to be used for the generation of the segment.
        """
        if isinstance(data, Point):
            out = data
        elif isinstance(data, pd.DataFrame):
            out = Point(data)
        else:

            # check the data
            if isinstance(data, list):
                val = np.array(data)
            elif isinstance(data, np.ndarray):
                val = data
            else:
                txt = "amplitude_data and origin_data must be an instance of "
                txt += "[List, numpy.ndarray, pandas.DataFrame, Point]."
                raise ValueError(txt)
            if val.ndim == 1:
                val = np.atleast_2d(val).T
            elif val.ndim > 2:
                txt = "amplitude_data and origin_data must be a 1D or 2D array."
                raise ValueError(txt)

            # check the index
            if index is None:
                idx = np.arange(data.shape[0])
            else:
                idx = self._adjust_indices(index)
            txt = "index has length {}, but it should be {}."
            txt = txt.format(len(idx), val.shape[0])
            assert len(idx) == val.shape[0], txt

            # check the columns
            if columns is None:
                col = np.array(["D{}".format(i + 1) for i in range(data.shape[1])])
            else:
                col = self._adjust_indices(columns)
            txt = "columns has length {}, but it should be {}."
            txt = txt.format(len(col), val.shape[1])
            assert len(col) == val.shape[1], txt

            # generate the Point object
            out = Point(data=val, index=idx, columns=col)

        return out

    def __init__(
        self,
        p0_data: Tuple[Point, pd.DataFrame, np.ndarray, list],
        p1_data: Tuple[Point, pd.DataFrame, np.ndarray, list],
        index: Tuple[list, np.ndarray] = None,
        columns: Tuple[list, np.ndarray] = None,
    ):
        # get p0 and p1 as Point instances.
        p0 = self._get_data(p0_data, index, columns)
        p1 = self._get_data(p1_data, index, columns)

        # check amplitude and origin matches with each other
        txt = "p0_data and p1_data must have the same shape."
        assert p0.matches(p1), txt

        # create the segment
        self.p0 = p0
        self.p1 = p1

        # set the indexers .loc and .iloc
        self.loc = _Indexer(
            attr="loc",
            obj=self,
            p0=self.p0,
            p1=self.p1,
        )
        self.iloc = _Indexer(
            attr="iloc",
            obj=self,
            p0=self.p0,
            p1=self.p1,
        )

    def _get_item(self, item):
        """
        ensure that item is an iterable object.

        Parameters
        ----------
        item: Any
            the item attribute passed to __setitem__ or __getitem__.

        Returns
        -------
        itm: iterable
            an iterable version of item.
        """
        if isinstance(item, str) or not hasattr(item, "__iter__"):
            return [item]
        else:
            return item

    def __setitem__(self, item, value):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        value: any
            the value to be set for the provided item.
        """
        itm = self._get_item(item)

        try:
            self.loc.__setitem__(itm, value)
        except KeyError:
            try:
                self.loc.__setitem__(np.s_[:, itm], value)
            except (IndexError, AttributeError):
                try:
                    self.iloc.__setitem__(itm, value)
                except KeyError:
                    self.iloc.__setitem__(np.s_[:, itm], value)
        except (IndexError, AttributeError):
            try:
                self.iloc.__setitem__(itm, value)
            except KeyError:
                self.iloc.__setitem__(np.s_[:, itm], value)

    def __getitem__(self, item):
        """
        set items by index in a numpy fashion style.

        Parameters
        ----------
        item: str
            the item to be set.

        Returns
        -------
        val: Vector
            the (sliced) vector.
        """
        itm = self._get_item(item)

        try:
            return self.loc.__getitem__(itm)
        except KeyError:
            try:
                return self.loc.__getitem__(np.s_[:, itm])
            except (ValueError, TypeError):
                try:
                    return self.iloc.__getitem__(itm)
                except KeyError:
                    return self.iloc.__getitem__(np.s_[:, itm])
        except (ValueError, TypeError):
            try:
                return self.iloc.__getitem__(itm)
            except KeyError:
                return self.iloc.__getitem__(np.s_[:, itm])

    def pivot(self) -> pd.DataFrame:
        """
        generate a wide dataframe object containing both origin and amplitudes.
        """
        df = self.stack().pivot("Time", ["Source", "Dimension"])
        df.columns = pd.Index([i[1:] for i in df.columns])
        return df

    def get_angle(self, x: str, y: str, name: str = None) -> Point:
        """
        return the angle between dimensions y and x using the arctan function.

        Parameters
        ----------
        x, y: str
            the name of the columns to be used for the angle calculation.

        name: str or None
            the name of the output dataframe column

        Returns
        -------
        q: Point
            the angle in radiants.
        """
        return (self.p1 - self.p0).get_angle(x, y, name)

    def _get_vals(self, obj):
        """
        hidden function used to extract the values to be used
        for math operations with segments.

        Parameters
        ----------
        obj: Any
            the second object included in the math operation.

        Returns
        -------
        val0, val1: Any
            the values to be used for the math operation with
            respectively p0 and p1.
        """
        if isinstance(obj, Vector):
            val0 = obj.amplitude
            val1 = obj.amplitude
        elif isinstance(obj, Segment):
            val0 = obj.p0
            val1 = obj.p1
        else:
            val0 = obj
            val1 = obj
        return val0, val1

    def __iadd__(self, obj):
        """
        iterative addition.
        """
        self = self + obj
        return self

    def __radd__(self, obj):
        """
        right addition.
        """
        return self + obj

    def __add__(self, obj):
        """
        addition.
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 + val0, p1_data=self.p1 + val1)

    def __isub__(self, obj):
        """
        iterative subtraction.
        """
        self = self - obj
        return self

    def __rsub__(self, obj):
        """
        right subtraction.
        """
        return -self + obj

    def __sub__(self, obj):
        """
        subtraction.
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 - val0, p1_data=self.p1 - val1)

    def __imul__(self, obj):
        """
        iterative multiplication.
        """
        self = self * obj
        return self

    def __rmul__(self, obj):
        """
        right multiplication.
        """
        return self * obj

    def __mul__(self, obj):
        """
        multiplication
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 * val0, p1_data=self.p1 * val1)

    def __itruediv__(self, obj):
        """
        iterative division.
        """
        self = self / obj
        return self

    def __rtruediv__(self, obj):
        """
        iterative division.
        """

        return obj * (self ** (-1))

    def __truediv__(self, obj):
        """
        division
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 / val0, p1_data=self.p1 / val1)

    def __ifloordiv__(self, obj):
        """
        iterative floor division.
        """
        self = self / obj
        return self

    def __floordiv__(self, obj):
        """
        floor division
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 // val0, p1_data=self.p1 // val1)

    def __pow__(self, obj):
        """
        power elevation (** operator).
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 ** val0, p1_data=self.p1 ** val1)

    def __abs__(self):
        """
        absolute value
        """
        return Segment(p0_data=abs(self.p0), p1_data=abs(self.p1))

    def __mod__(self, obj):
        """
        module (% operator).
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 % val0, p1_data=self.p1 % val1)

    def __neg__(self):
        """
        negative of self (- operator).
        """
        return self * (-1)

    def __pos__(self):
        """
        positive of self (+ operator).
        """
        return self * (1)

    def __truth__(self):
        """
        truth (identity) operator.
        """
        return self

    def __matmul__(self, obj):
        """
        matrix multiplication (@ operator).
        """
        val0, val1 = self._get_vals(obj)
        return Segment(p0_data=self.p0 @ val0, p1_data=self.p1 @ val1)


class ReferenceFrame:
    """
    Create a ReferenceFrame instance.

    Parameters
    ----------

    origin: pd.DataFrame
        a pandas.DataFrame that contains the coordinates of the
        ReferenceFrame's origin at each time instant (index).

    versors: dict
        a dict where each key is a pandas.DataFrame with shape equal to origin
        that contains coordinates of the versors defining the orientation of
        the reference frame at each time instant.
        The number of versors must be equal to the number of dimensions of 'origin'.
    """

    def __init__(self, origin: Tuple[pd.DataFrame, Point], versors: dict):

        # check the origin
        txt = "'origin' must be a pandas.DataFrame."
        assert isinstance(origin, (Point, pd.DataFrame)), txt
        idx = origin.index.to_numpy()
        txt = "origin's index must be numeric."
        assert all([isinstance(i, (int, float)) for i in idx]), txt
        cols = origin.columns.to_numpy()
        assert 2 <= len(cols) <= 3, "only 2D and 3D frames are supported."
        self.origin = origin

        # check the versors
        self.versors = {}
        txt = "'versors' must be a dict."
        assert isinstance(origin, dict), txt
        assert len(versors) == len(cols), "versors must have len {}".format(len(cols))
        for key, value in versors.items():
            txt = "'{}' must have shape {}x{}".format(key, len(idx), len(cols))
            assert isinstance(value, (Point, pd.DataFrame)), txt
            assert len(idx) == value.shape[0], txt
            assert len(cols) == value.shape[1], txt
            txt = "{} index must be the same as origin.".format(key)
            assert all([i in idx for i in value.index.to_numpy()]), txt
            txt = "{} columns must be the same as origin.".format(key)
            assert all([i in cols for i in value.columns.to_numpy()]), txt

        # apply gram-schmidt normalization to the versors
        self.versors = versors.copy()
        mat = np.zeros((len(idx), len(cols), len(cols)))
        for i, v in enumerate(idx):
            vers = np.vstack([k.loc[v].values.T for k in self.versors.values()])
            norm = self._gram_schmidt(vers)
            for j, key in enumerate(self.versors):
                self.versors[key].loc[v, cols] = norm[j]
            mat[i] = norm

        # store the efficient scipy.Rotation class object allowing the rotation
        # of additional input segments.
        self._rotmat = R.from_matrix(mat)

    def stack(self):
        """
        Convert the ReferenceFrame into a long-format pandas DataFrame object.

        Returns
        -------
        out: pd.DataFrame
            a pandas DataFrame containing all the relevant data of the frame.
        """
        out = self.origin.stack()
        out.insert(0, "Source", np.tile("Origin", out.shape[0]))
        for i, v in self.versors.items():
            df = v.stack()
            df.insert(0, "Source", np.tile(i, df.shape[0]))
            out = out.append(df, ignore_index=True)
        return out

    @staticmethod
    def unstack(df: pd.DataFrame):
        """
        generate a ReferenceFrame object from a DataFrame.

        Parameters
        ----------

        df: pandas.DataFrame
            a pandas.DataFrame sorted as it would be generated by the
            ReferenceFrame.stack() method.

        Returns
        -------

        frame: ReferenceFrame
            the ReferenceFrame instance resulting from the dataframe reading.
        """

        def _extract(df, src):
            """
            extract the point corresponding to src from the input df.

            Parameters
            ----------
            df: pandas.DataFrame
                a stacked df as resulting from ReferenceFrame.stack()

            src: str
                the source from which the point is required.

            Returns
            -------
            pnt: Point
                the extracted Point.
            """
            pnt = df.loc[df.isin([src]).any(1)][["Time", "Dimension", "Amplitude"]]
            return Point.unstack(pnt)

        # get the versors
        srcs = np.unique(df["Source"].values.flatten())
        vs = {i: _extract(df, i) for i in srcs if i != "Origin"}

        # get the origin
        o = _extract(df, "Origin")

        # return a ReferenceFrame instance
        return ReferenceFrame(origin=o, versors=vs)

    def pivot(self):
        """
        arrange the object as multiindex dataframe.
        """
        return self.stack().pivot("Time", ["Source", "Dimension"])

    def __str__(self):
        """
        generate a pandas.DataFrame representing the ReferenceFrame.
        """
        return self.pivot().__str__()

    def matches(self, obj) -> bool:
        """
        Check obj may is rotable.

        Parameters
        ----------
        obj: Any
            a Point or Point object.

        Returns
        -------
        matches: bool
            True if obj can be rotated according to the current
            ReferenceFrame instance. False, otherwise.
        """
        return isinstance(obj, (Point, Vector, Segment)) & obj.matches(self.origin)

    def copy(self):
        """
        Return a copy of self.
        """
        return ReferenceFrame(
            origin=self.origin.copy(),
            versors=self.versors.copy(),
        )

    def _apply_rotation(self, pnt):
        """
        rotate the Point according to the ReferenceFrame object and
        rotation matrix.

        Parameters
        ----------
        pnt: Point
            the point to be rotated.

        Returns
        -------
        rot: Point
            the rotated point
        """
        vals = self._rotmat.apply((pnt - self.origin).values)
        return Point(vals, index=pnt.index, columns=pnt.columns)

    def _invert_rotation(self, pnt):
        """
        rotate the Point back to the global frame according to the
        ReferenceFrame object and rotation matrix.

        Parameters
        ----------
        pnt: Point
            the point to be rotated.

        Returns
        -------
        rot: Point
            the rotated point
        """
        vals = self._rotmat.inv().apply(pnt.values) + self.origin
        return Point(vals, index=pnt.index, columns=pnt.columns)

    def _apply(self, obj, fun):
        """
        rotate the object from or to the ReferenceFrame according to fun.

        Parameters
        ----------
        obj: Point, Vector, Segment
            the object to be rotated.

        fun: function
            the rotation function.

        Returns
        -------
        rot: Point, Vector, Segment
            the rotated object.
        """
        txt = "'obj' cannot be rotated by the current ReferenceFrame."
        assert self.matches(obj), txt
        if isinstance(obj, Point):
            out = fun(obj)
        elif isinstance(obj, Vector):
            out = Vector(origin=fun(obj.origin), amplitude=fun(obj.amplitude))
        elif isinstance(fun, Segment):
            out = Segment(p0_data=fun(obj.p0), p1_data=fun(obj.p1))
        return out

    def rotate(
        self,
        obj: Tuple[Point, Vector, Segment],
    ) -> Tuple[Point, Vector, Segment]:
        """
        Rotate point according to the current ReferenceFrame instance.

        Parameters
        ----------
        obj: Point, Vector, Segment
            the object to be rotated.

        Returns
        -------
        rot: Point, Vector, Segment
            the rotated object.
        """
        return self._apply(obj, self._apply_rotation)

    def invert(
        self,
        obj: Tuple[Point, Vector, Segment],
    ) -> Tuple[Point, Vector, Segment]:
        """
        Rotate point back from the current ReferenceFrame to its former one.

        Parameters
        ----------
        obj: Point, Vector, Segment
            the object to be rotated.

        Returns
        -------
        rot: Point, Vector, Segment
            the rotated object.
        """
        return self._apply(obj, self._invert_rotation)

    def _gram_schmidt(self, points: np.ndarray) -> np.ndarray:
        """
        Return the orthogonal basis defined by a set of points using the
        Gram-Schmidt algorithm.

        Parameters:
            points (np.ndarray): a NxN numpy.ndarray to be orthogonalized (by row).

        Returns:
            a NxN numpy.ndarray containing the orthogonalized arrays.
        """

        def proj(a, b):
            return (np.inner(a, b) / np.inner(b, b) * b).astype(float)

        def norm(v):
            return v / np.sqrt(np.sum(v ** 2))

        # calculate the projection points
        W = []
        for i, u in enumerate(points):
            w = np.copy(u).astype(float)
            for j in points[:i, :]:
                w -= proj(u, j)
            W += [w]

        # normalize
        return np.vstack([norm(u) for u in W])

    @property
    def sampling_frequency(self) -> float:
        """
        return the sampling frequency of the object.
        """
        return self.origin.sampling_frequency


#! METHODS


def three_points_angle(a: Point, b: Point, c: Point, name: str = None):
    """
    return the angle between 3 points using the cosine theorem.

    Parameters
    ----------
    a, b, c: Point
        the point objects.

    name: str or None
        the name of the column in the output dataframe

    Returns
    -------
    q: Point
        the angle in radiants.
    """

    # check the data
    if name is None:
        name = "Angle"
    assert isinstance(name, str), "name must be a string"
    assert a.matches(b), "a does not match b"
    assert a.matches(c), "a does not match c"
    assert b.matches(c), "b does not match c"

    # get the segments
    ab = (b - a).norm.values.flatten()
    bc = (b - c).norm.values.flatten()
    ac = (c - a).norm.values.flatten()

    # return the angle
    q = np.arccos((ac ** 2 - ab ** 2 - bc ** 2) / (-2 * ab * bc))
    return Point(q, columns=[name], index=a.index)
